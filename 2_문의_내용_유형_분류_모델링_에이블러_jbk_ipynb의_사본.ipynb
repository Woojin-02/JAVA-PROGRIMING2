{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Woojin-02/JAVA-PROGRIMING2/blob/main/2_%EB%AC%B8%EC%9D%98_%EB%82%B4%EC%9A%A9_%EC%9C%A0%ED%98%95_%EB%B6%84%EB%A5%98_%EB%AA%A8%EB%8D%B8%EB%A7%81_%EC%97%90%EC%9D%B4%EB%B8%94%EB%9F%AC_jbk_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcFHpUTGNVLe"
      },
      "source": [
        "# **미니프로젝트 4차 1대1 문의 내용 유형 분류기**\n",
        "# 단계3 : Text classification\n",
        "\n",
        "### 문제 정의\n",
        "> 1:1 문의 내용 분류 문제<br>\n",
        "> 1. 문의 내용 분석\n",
        "> 2. 문의 내용 분류 모델 성능 평가\n",
        "### 학습 데이터\n",
        "> * 1:1 문의 내용 데이터 : train.csv\n",
        "\n",
        "### 변수 소개\n",
        "> * text : 문의 내용\n",
        "> * label : 문의 유형\n",
        "\n",
        "### References\n",
        "> * Machine Learning\n",
        ">> * [sklearn-tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
        "> * Deep Learning\n",
        ">> * [Google Tutorial](https://developers.google.com/machine-learning/guides/text-classification)\n",
        ">> * [Tensorflow Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)\n",
        ">> * [Keras-tutorial](https://keras.io/examples/nlp/text_classification_from_scratch/)\n",
        ">> * [BERT-tutorial](https://www.tensorflow.org/text/guide/bert_preprocessing_guide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlRWJB2w6Ip6"
      },
      "source": [
        "## 1. 개발 환경 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDQWUjJgNVLi"
      },
      "source": [
        "### 1-1. 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ioeAIOVZNVLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c79899-294d-4ce5-bc43-6ad4562b8ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.2)\n",
            "Requirement already satisfied: python-mecab-ko in /usr/local/lib/python3.10/dist-packages (1.3.3)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (9.4.0)\n",
            "Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.10/dist-packages (from python-mecab-ko) (2.1.1.post2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "# 필요 라이브러리부터 설치할께요.\n",
        "!pip install konlpy pandas seaborn wordcloud python-mecab-ko wget transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy8nheIqNVLj"
      },
      "source": [
        "### 1-2. 라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vdLv3wY8NVLj"
      },
      "outputs": [],
      "source": [
        "from mecab import MeCab\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import wget,os\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import wget,os\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rrlClPUZNVLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eedadc1-5460-4195-916b-84ef511314df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20200506-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "# 런타임 재시작 필요\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTyLBKvHNVLl"
      },
      "source": [
        "### 1-3. 한글 글꼴 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b3EdAJgdNVLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4972907e-1d1f-433b-f611-d313dba5e3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20200506-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NSXviiZ7NVLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2786c9e5-76f2-4dd8-c739-fb65caf40ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NanumGothic\n"
          ]
        }
      ],
      "source": [
        "FONT_PATH = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_name = fm.FontProperties(fname=FONT_PATH, size=10).get_name()\n",
        "print(font_name)\n",
        "plt.rcParams['font.family']=font_name\n",
        "assert plt.rcParams['font.family'] == [font_name], \"한글 폰트가 설정되지 않았습니다.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K8Sp4ejNVLm"
      },
      "source": [
        "### 1-4. 구글드라이브 연결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_NrJV5saNVLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c2d268-fea7-47cb-e29a-dc9ce957d2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKI84v2TNVLm"
      },
      "source": [
        "## 2. 전처리한 데이터 불러오기\n",
        "* 1, 2일차에 전처리한 데이터를 불러옵니다.\n",
        "* sparse data에 대해서는 scipy.sparse.load_npz 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "mhyLBaitNVLm"
      },
      "outputs": [],
      "source": [
        "# 파일 경로 지정\n",
        "PATH = '/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/'\n",
        "\n",
        "# npy 파일 불러오기\n",
        "x_mor_sequence_train = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_mor_sequence_train.npy\")\n",
        "x_mor_sequence_val = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_mor_sequence_val.npy\")\n",
        "\n",
        "x_pr_train = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_pr_train.npy\")\n",
        "x_pr_val = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_pr_val.npy\")\n",
        "\n",
        "x_w2v_train = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_w2v_train.npy\")\n",
        "x_w2v_val = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_w2v_val.npy\")\n",
        "\n",
        "y_train = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/y_train.npy\")\n",
        "y_val = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/y_val.npy\")\n",
        "\n",
        "x_mor_sequence_test = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_mor_sequence_te.npy\")\n",
        "x_pr_test = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_pr_te.npy\")\n",
        "x_w2v_test = np.load(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_w2v_te.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "# npz 파일 불러오기\n",
        "x_tfidf_train = sparse.load_npz(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_tfidf_train.npz\")\n",
        "x_tfidf_val = sparse.load_npz(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_tfidf_val.npz\")\n",
        "x_tfidf_test = sparse.load_npz(\"/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/X_tfidf_te.npz\")"
      ],
      "metadata": {
        "id": "UWHRsqFzItk2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = pd.read_csv('/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/test.csv')"
      ],
      "metadata": {
        "id": "9Qxty82jqw_4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/2023.10.16_미니프로젝트4차_실습자료/train.csv')\n",
        "label_dict = {\n",
        "    '코드1': 0,\n",
        "    '코드2': 0,\n",
        "    '웹': 1,\n",
        "    '이론': 2,\n",
        "    '시스템 운영': 3,\n",
        "    '원격': 4\n",
        "}\n",
        "preprocessed_df = train.replace({'label':label_dict}).copy()\n",
        "x_train, x_val, _, _ = train_test_split(preprocessed_df.text, preprocessed_df.label, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "1VD-egd8SX3f"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_P-yHLLNVLm"
      },
      "source": [
        "## 3. Machine Learning(N-grams)\n",
        "* N-gram으로 전처리한 데이터를 이용하여 3개 이상의 Machine Learning 모델 학습 및 성능 분석\n",
        "> * [sklearn-tutorial](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_04HBUEaNVLm"
      },
      "source": [
        "### 3-1. Model 1 : RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MWjm4sCNVLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5f387a-0ff4-457e-d1db-c57d14f225c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.7367853290183387\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.95      0.80       392\n",
            "           1       0.79      0.56      0.66       179\n",
            "           2       0.76      0.49      0.60       195\n",
            "           3       0.85      0.71      0.77       130\n",
            "           4       1.00      0.71      0.83        31\n",
            "\n",
            "    accuracy                           0.74       927\n",
            "   macro avg       0.82      0.68      0.73       927\n",
            "weighted avg       0.76      0.74      0.73       927\n",
            "\n",
            "[0.43109015 0.43325167 0.44765053 0.432529   0.43324843 0.43073174\n",
            " 0.42965131 0.42929159 0.42929159 0.43001102 0.42929159 0.42929159\n",
            " 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159\n",
            " 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159\n",
            " 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159\n",
            " 0.43649167 0.43900966 0.43756433 0.43936678 0.44548188 0.43792598\n",
            " 0.43037073 0.43396915 0.42965195 0.42965195 0.43181088 0.43037073\n",
            " 0.42965131 0.43288872 0.43360814 0.42965131 0.43001102 0.42929159\n",
            " 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159\n",
            " 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159 0.42929159\n",
            " 0.44008879 0.45592067 0.45016138 0.45411627 0.44979973 0.43936742\n",
            " 0.44477283 0.43756498 0.43720591 0.44296325 0.43324843 0.4354067\n",
            " 0.44260354 0.43361073 0.43360879 0.43397109 0.43181023 0.43073044\n",
            " 0.42929159 0.43109015 0.43145052 0.43073044 0.43001102 0.43145181\n",
            " 0.4325303  0.43001102 0.43073044 0.43216929 0.42929159 0.42929159\n",
            " 0.43684814 0.44116987 0.44943677 0.46059304 0.47175903 0.4566375\n",
            " 0.45088081 0.44800052 0.44044397 0.45016333 0.44044397 0.45412729\n",
            " 0.44008944 0.43360879 0.43324972 0.43468987 0.43432756 0.43540735\n",
            " 0.43720721 0.43288872 0.43397109 0.43864994 0.43396915 0.43648713\n",
            " 0.43144987 0.43324972 0.43144987 0.43396785 0.43612872 0.43577095\n",
            " 0.45052887 0.46097025 0.45843736 0.46743146 0.47284594 0.4645583\n",
            " 0.47103182 0.4523216  0.46060406 0.46061313 0.45735693 0.45088081\n",
            " 0.45052434 0.45196059 0.45231512 0.45555253 0.44584808 0.43900382\n",
            " 0.45232095 0.43972519 0.44009139 0.44152375 0.43936354 0.43504764\n",
            " 0.44368138 0.44044656 0.43648584 0.43756562 0.44584289 0.44044397\n",
            " 0.44548188 0.46419924 0.48039147 0.49081794 0.49226521 0.49334824\n",
            " 0.47967399 0.47247456 0.46815348 0.4613183  0.46564132 0.47066628\n",
            " 0.47499838 0.45196059 0.47211614 0.4598801  0.45843347 0.45915613\n",
            " 0.45771923 0.45519671 0.45772053 0.45556225 0.461317   0.45052434\n",
            " 0.45520708 0.45772053 0.45160088 0.45303649 0.45124376 0.45700175\n",
            " 0.44944131 0.47679111 0.50234818 0.49729535 0.48757535 0.49837967\n",
            " 0.50126126 0.48472357 0.49442738 0.48470542 0.48254002 0.47390628\n",
            " 0.47390952 0.49046082 0.49622464 0.4843496  0.48614622 0.47139607\n",
            " 0.47031888 0.47966492 0.50053665 0.47391665 0.47247326 0.4731888\n",
            " 0.47751572 0.4692378  0.46347592 0.46095405 0.46455895 0.47715471\n",
            " 0.4447495  0.46528745 0.49405924 0.5091691  0.5163763  0.49694925\n",
            " 0.51169421 0.52932465 0.48830644 0.50269946 0.50305723 0.4983868\n",
            " 0.49803033 0.5062927  0.49911854 0.48866031 0.50485125 0.4933437\n",
            " 0.47679305 0.49011407 0.48830773 0.48398859 0.4861527  0.48830903\n",
            " 0.48758377 0.48003046 0.48002981 0.48613974 0.48938168 0.48613714\n",
            " 0.44944779 0.48686435 0.48327241 0.52320954 0.5350768  0.51566531\n",
            " 0.51709249 0.51888781 0.51852421 0.50918141 0.51205198 0.52644047\n",
            " 0.52536004 0.5242809  0.5250094  0.5041409  0.51924882 0.50269622\n",
            " 0.51925595 0.4994614  0.50450321 0.50198198 0.50629399 0.50736924\n",
            " 0.51349861 0.50701925 0.49802126 0.49946659 0.50341565 0.50413118\n",
            " 0.46024499 0.47606002 0.48687536 0.5217694  0.53077322 0.54444164\n",
            " 0.55127811 0.53077063 0.53077063 0.53473848 0.53112127 0.52464774\n",
            " 0.53543976 0.52967982 0.5307797  0.51421609 0.535443   0.53220948\n",
            " 0.52249789 0.53220364 0.51817422 0.53365416 0.52357185 0.51350444\n",
            " 0.52968436 0.5253717  0.52428997 0.51457969 0.52177134 0.51925465\n",
            " 0.45987361 0.50090479 0.51096766 0.53473459 0.55199883 0.54515717\n",
            " 0.54516625 0.55198652 0.54156783 0.55488042 0.55199041 0.52860134\n",
            " 0.54191587 0.5523553  0.53939529 0.55919308 0.53221142 0.5448007\n",
            " 0.53473135 0.54695897 0.53615918 0.53617409 0.5595677  0.5448007\n",
            " 0.54876078 0.54013351 0.538683   0.54372027 0.53616307 0.53904336\n",
            " 0.45124959 0.49226133 0.50017111 0.54012703 0.54373064 0.54659667\n",
            " 0.54263659 0.55740294 0.56566142 0.57107784 0.55235725 0.5548694\n",
            " 0.55343574 0.54479551 0.57394582 0.55343574 0.56350768 0.54300214\n",
            " 0.55847819 0.56099229 0.56567373 0.57143107 0.55631992 0.5631538\n",
            " 0.54876402 0.55056063 0.56423294 0.56567697 0.55919826 0.55451682\n",
            " 0.46023138 0.50162486 0.51456867 0.52967853 0.54192689 0.55451812\n",
            " 0.5635187  0.56962927 0.57827857 0.56927474 0.57286862 0.56315445\n",
            " 0.56423683 0.56747035 0.58617603 0.57502625 0.56782941 0.56748137\n",
            " 0.57000324 0.55847171 0.58293344 0.57034869 0.56495755 0.57215568\n",
            " 0.58366194 0.57934474 0.56530689 0.56531337 0.56531402 0.58726489\n",
            " 0.4703111  0.50917752 0.53651176 0.54300862 0.548042   0.56243762\n",
            " 0.57071424 0.56818783 0.5897738  0.58005963 0.58223346 0.56999352\n",
            " 0.57718128 0.57755007 0.58006287 0.58654806 0.58617927 0.58223216\n",
            " 0.58690583 0.5840223  0.5962752  0.60093396 0.57826755 0.60237864\n",
            " 0.58258474 0.60597382 0.5876259  0.58726424 0.59230605 0.59769655\n",
            " 0.47643658 0.49728628 0.5329276  0.53003111 0.55955798 0.56459071\n",
            " 0.57287057 0.58977445 0.57682092 0.59194633 0.59195152 0.58941733\n",
            " 0.59841921 0.60669583 0.58151403 0.5984218  0.61065332 0.59697582\n",
            " 0.61208244 0.60561475 0.59265539 0.59841467 0.60957483 0.60993972\n",
            " 0.60021648 0.59698036 0.60993324 0.61100266 0.60884309 0.60921187\n",
            " 0.45592067 0.51890077 0.5286143  0.57035064 0.58006028 0.57393934\n",
            " 0.58473265 0.58223022 0.59948474 0.60273965 0.59050813 0.59733878\n",
            " 0.59841143 0.61605937 0.59914058 0.59950612 0.61028583 0.61496662\n",
            " 0.6056154  0.6056154  0.6153367  0.60309871 0.61137792 0.62288223\n",
            " 0.60957872 0.61353296 0.62613001 0.6192903  0.61209411 0.61173051\n",
            " 0.48651112 0.51063322 0.53401581 0.56099812 0.57466978 0.58223151\n",
            " 0.59482338 0.60021388 0.60848921 0.60416294 0.61641454 0.61028583\n",
            " 0.61317325 0.60957936 0.6084931  0.6243334  0.62217124 0.62397304\n",
            " 0.61784432 0.62396591 0.61208503 0.63548188 0.63871994 0.61713202\n",
            " 0.61928835 0.6185618  0.6297213  0.63367619 0.62649426 0.64159505\n",
            " 0.46311167 0.50844578 0.54588113 0.56098062 0.59373388 0.56782876\n",
            " 0.59589928 0.59769719 0.59877892 0.61389332 0.62360555 0.61388878\n",
            " 0.61930002 0.61317    0.62792987 0.63981204 0.61928706 0.6239685\n",
            " 0.64268002 0.6282844  0.62648454 0.62828958 0.63691749 0.63979778\n",
            " 0.6441234  0.62827986 0.62972908 0.63008361 0.63728174 0.63907577\n",
            " 0.4706773  0.50593946 0.53940048 0.5606423  0.57465682 0.59122173\n",
            " 0.60417266 0.6030864  0.62576706 0.6120954  0.62179986 0.62036555\n",
            " 0.62396656 0.61713267 0.632599   0.62541513 0.64951196 0.62468468\n",
            " 0.62972714 0.63296455 0.63331713 0.64123339 0.64087433 0.62288807\n",
            " 0.64160736 0.64231771 0.65490699 0.65562966 0.64087822 0.63585197\n",
            " 0.47283687 0.52609502 0.54552985 0.57324908 0.57646315 0.61245641\n",
            " 0.60345194 0.59588502 0.62864346 0.61604446 0.62216216 0.6275559\n",
            " 0.63439821 0.64520254 0.64232095 0.62971936 0.63979584 0.64699397\n",
            " 0.63620325 0.65383175 0.64844384 0.64123987 0.64879707 0.64951714\n",
            " 0.65742757 0.65023462 0.65419599 0.64448506 0.64735498 0.65887161\n",
            " 0.4767937  0.51529717 0.55019314 0.56676    0.57682675 0.5890654\n",
            " 0.61676648 0.62504699 0.60273381 0.62504569 0.62324648 0.62540281\n",
            " 0.62684685 0.63943872 0.6340372  0.65024046 0.62900706 0.65131311\n",
            " 0.64735628 0.65238966 0.65922484 0.65671528 0.64520189 0.64664463\n",
            " 0.64447858 0.6577996  0.66463219 0.6635362  0.66642751 0.66173893\n",
            " 0.48435803 0.51709378 0.54516754 0.58799209 0.57935381 0.61928965\n",
            " 0.60633936 0.62720073 0.63008296 0.62828505 0.62648649 0.62648325\n",
            " 0.63692721 0.65311167 0.63043684 0.644837   0.63764729 0.65778339\n",
            " 0.64374814 0.65599132 0.67542161 0.6621155  0.65886966 0.66102988\n",
            " 0.66607168 0.66499773 0.66427053 0.67003176 0.66571456 0.65958584\n",
            " 0.47282714 0.50918206 0.55559336 0.58545985 0.59013676 0.58690647\n",
            " 0.59734137 0.61244928 0.61928122 0.62432238 0.64843217 0.64304362\n",
            " 0.63475144 0.65742757 0.64843217 0.65995722 0.64123663 0.66103636\n",
            " 0.65347916 0.65634843 0.65815218 0.66714888 0.66030916 0.66534837\n",
            " 0.66678203 0.6603111  0.66212003 0.65958325 0.68406378 0.66139218\n",
            " 0.49081988 0.52571456 0.53687601 0.570711   0.58259058 0.61425757\n",
            " 0.6163964  0.62288677 0.60561216 0.62865383 0.62431719 0.65274742\n",
            " 0.645909   0.66462376 0.65023851 0.65852486 0.65347463 0.66067211\n",
            " 0.6538311  0.66067211 0.66355629 0.66210318 0.66859226 0.66822412\n",
            " 0.66570743 0.65491477 0.66427831 0.66930002 0.67685722 0.66787154\n",
            " 0.47140061 0.51996241 0.55882948 0.58042064 0.60705619 0.63440858\n",
            " 0.61676907 0.61533217 0.62431849 0.62360944 0.63188282 0.64412211\n",
            " 0.641958   0.65131959 0.66318945 0.65814959 0.65778728 0.66931104\n",
            " 0.65455311 0.66498477 0.66642297 0.66606779 0.66822607 0.66750016\n",
            " 0.67325815 0.68765312 0.67830773 0.67507032 0.68190745 0.67937131\n",
            " 0.49333917 0.51960788 0.56459654 0.5606235  0.59446756 0.60057619\n",
            " 0.62863957 0.62576577 0.63116145 0.63008555 0.63872318 0.65599067\n",
            " 0.65563873 0.64916391 0.67361916 0.65815088 0.65635686 0.66678916\n",
            " 0.66534837 0.66894873 0.67541707 0.67506579 0.67182449 0.67937909\n",
            " 0.66714369 0.66642232 0.6772273  0.67470348 0.66822866 0.6764975\n",
            " 0.48685787 0.49765053 0.56530883 0.58293214 0.59193791 0.59770043\n",
            " 0.62072331 0.62181541 0.64087368 0.62864217 0.63043814 0.64375203\n",
            " 0.6462752  0.65525958 0.65274613 0.64303908 0.66714628 0.67110701\n",
            " 0.66606974 0.67614816 0.66571197 0.67650139 0.67254197 0.68838227\n",
            " 0.668578   0.68262104 0.66859032 0.67398406 0.68585715 0.68477802\n",
            " 0.48363471 0.50918336 0.54948927 0.58367036 0.5944546  0.60454015\n",
            " 0.60094044 0.62215763 0.63331843 0.6567062  0.65275261 0.64268002\n",
            " 0.65167542 0.65671204 0.66247975 0.65526671 0.66931233 0.67109988\n",
            " 0.6718355  0.67038758 0.66282131 0.67182708 0.66534383 0.68549031\n",
            " 0.67902262 0.68802126 0.68297945 0.67183097 0.68513967 0.68621427\n",
            " 0.48398665 0.54084516 0.54983019 0.56098516 0.58835505 0.60344222\n",
            " 0.6390803  0.62216281 0.63727721 0.64160412 0.65312075 0.65239484\n",
            " 0.645198   0.65814376 0.67110441 0.67326334 0.66714304 0.67254261\n",
            " 0.67146672 0.67146413 0.67686694 0.67361657 0.67757729 0.69052952\n",
            " 0.69017046 0.69053665 0.68333981 0.681177   0.68874003 0.67937844\n",
            " 0.4588042  0.52859809 0.56566336 0.58904984 0.60920669 0.61605289\n",
            " 0.63296325 0.62971288 0.62936354 0.64843736 0.64555059 0.65166764\n",
            " 0.64267483 0.66678916 0.67182384 0.66102729 0.67002204 0.65815737\n",
            " 0.67397757 0.67578262 0.67614363 0.66569447 0.69305269 0.6890991\n",
            " 0.68514162 0.68081988 0.69413183 0.687296   0.68009657 0.68837514]\n",
            "최적파라미터: {'max_depth': 30, 'n_estimators': 27}\n",
            "최고성능: 0.6941318296713981\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 파라미터 선언\n",
        "params = {'max_depth':range(1, 31), 'n_estimators':range(1, 31)}\n",
        "\n",
        "# 모델 생성\n",
        "model = GridSearchCV(RandomForestClassifier(), params, cv=5)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_tfidf_train, y_train)\n",
        "\n",
        "# 모델 평가\n",
        "y_pred = model.predict(x_tfidf_val)\n",
        "\n",
        "# 정확도 출력\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"정확도:\", accuracy)\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# 결과 확인\n",
        "print(model.cv_results_['mean_test_score'])  # 수행 정보 중 평균 성능값들 출력\n",
        "print('최적파라미터:', model.best_params_)    # 최적 파라미터\n",
        "print('최고성능:', model.best_score_)         # 최고성능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWBf8inLNVLn"
      },
      "source": [
        "### 3-2. Model 2 : SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUdxJeCWNVLn"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "clf = MultinomialNB().fit(x_tfidf_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultinomialNB()),\n",
        "])\n",
        "\n",
        "text_clf.fit(x_train, y_train)\n",
        "predicted = text_clf.predict(x_val)\n",
        "np.mean(predicted == y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4RBnipKPgJJ",
        "outputId": "8ca0b695-5887-419d-817f-c75cf46433c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5361380798274002"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None)),\n",
        "    ])\n",
        "\n",
        "text_clf.fit(x_train, y_train)\n",
        "predicted = text_clf.predict(x_val)\n",
        "np.mean(predicted == y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p8Yv0nTPgMB",
        "outputId": "b4cafdc4-19b5-4b73-f159-c40536ce69b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7756202804746494"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {\n",
        "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'clf__alpha': (1e-2, 1e-3),\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(x_train, y_train)\n",
        "predicted = gs_clf.predict(x_val)\n",
        "np.mean(predicted == y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyStX6FGS2pH",
        "outputId": "e4379388-e369-43f9-dfda-e8685c80704a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7756202804746494"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlHRkL_3NVLn"
      },
      "source": [
        "### 3-3. Model 3 : xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjl-YWQGNVLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8442dd-ccf5-404a-975b-691b3ea74dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 파라미터 선언\n",
        "params = {'max_depth':range(1, 10)}\n",
        "\n",
        "# 모델 생성\n",
        "model_xgb = GridSearchCV(XGBClassifier(), params, cv=5)\n",
        "\n",
        "# 모델 학습\n",
        "model_xgb.fit(x_tfidf_train, y_train)\n",
        "\n",
        "# 모델 평가\n",
        "y_pred = model.predict(x_tfidf_val)\n",
        "\n",
        "# 정확도 출력\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"정확도:\", accuracy)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "bmZiRO_nUXk3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "08ff9e2f-a77d-4291-c2f9-606c941964c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ac529ead25dc>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tfidf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 모델 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1513\u001b[0m             )\n\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1516\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m             _check_call(\n\u001b[0;32m-> 2050\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2051\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m                 )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-4. Model 4 : Logistic Regression"
      ],
      "metadata": {
        "id": "_um4Hk5hflBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "LMQCLk7sflKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression 모델 생성 및 학습\n",
        "model = LogisticRegression()\n",
        "model.fit(x_tfidf_train, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred = model.predict(x_tfidf_val)\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "# conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "class_report = classification_report(y_val, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)"
      ],
      "metadata": {
        "id": "4Yjub1l4fvno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4663a5-ba2a-4328-e63a-115213a608f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8284789644012945\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.93      0.87       392\n",
            "           1       0.86      0.81      0.83       179\n",
            "           2       0.80      0.74      0.77       195\n",
            "           3       0.89      0.78      0.83       130\n",
            "           4       1.00      0.42      0.59        31\n",
            "\n",
            "    accuracy                           0.83       927\n",
            "   macro avg       0.87      0.74      0.78       927\n",
            "weighted avg       0.83      0.83      0.82       927\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_logistic = model.predict(x_tfidf_test)"
      ],
      "metadata": {
        "id": "PZsi7IGKqDc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_logistic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnXoNIa5vpb8",
        "outputId": "d1ae5459-e8b8-41a2-e5d4-c20336ac47ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0,\n",
              "       0, 0, 3, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
              "       0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 4, 4, 0, 2, 2, 0, 2, 0, 0, 0, 0, 3,\n",
              "       3, 2, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0,\n",
              "       0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 3,\n",
              "       3, 3, 0, 0, 0, 1, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
              "       0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 3, 2,\n",
              "       2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0,\n",
              "       0, 0, 0, 3, 3, 0, 3, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 3, 2, 2, 0, 0,\n",
              "       2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 4, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 2, 1, 0,\n",
              "       0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 4, 3, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 3, 2, 0, 3, 2, 2, 3, 0, 3, 0, 0, 0, 4, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 3, 0, 3, 0, 2, 2, 0, 0, 0, 3, 3, 2, 2, 0, 0, 0, 0, 2,\n",
              "       0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0,\n",
              "       3, 2, 1, 0, 0, 0, 1, 0, 2, 2, 2, 0, 2, 3, 2, 0, 0, 3, 0, 0, 2, 2,\n",
              "       0, 2, 2, 0, 0, 2, 3, 0, 0, 2, 2, 2, 0, 3, 2, 0, 0, 2, 2, 2, 2, 2,\n",
              "       2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
              "       0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
              "       0, 0, 0, 0, 2, 0, 0, 3, 3, 3, 3, 3, 2, 1, 1, 3, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 3, 0, 2, 4, 0, 3, 0, 2, 1, 0,\n",
              "       3, 0, 0, 0, 2, 3, 0, 3, 1, 1, 2, 1, 1, 0, 3, 1, 0, 1, 1, 2, 2, 0,\n",
              "       2, 3, 3, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
              "       3, 2, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 1, 3, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 4, 0,\n",
              "       2, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 2, 1, 0,\n",
              "       2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 3, 1, 1, 1, 1,\n",
              "       3, 2, 1, 0, 1, 0, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 0, 2, 1, 1, 0, 0, 2, 2, 2, 0, 1, 0, 1, 2, 2, 0, 0,\n",
              "       4, 1, 1, 1, 2, 1, 1, 3, 1, 3, 2, 3, 3, 0, 2, 0, 0, 0, 1, 0, 3, 2,\n",
              "       2, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3, 0, 3, 3, 0, 0,\n",
              "       0, 0, 0, 1, 2, 3, 1, 0, 1, 2, 4, 1, 0, 0, 0, 3, 2, 1, 1, 1, 1, 1,\n",
              "       1, 2, 4, 0, 1, 1, 2, 2, 1, 1, 0, 2, 0, 0, 2, 1, 1, 2, 2, 1, 1, 1,\n",
              "       1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 0, 1, 1, 2, 2, 2, 1, 1,\n",
              "       0, 2, 2, 2, 3, 2, 2, 3, 2, 3, 0, 1, 4, 0, 2, 2, 2, 2, 2, 0, 2, 2,\n",
              "       2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 1, 1, 3, 0, 3, 1, 3, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 3, 3, 4, 1, 1, 3, 0, 1, 0, 0, 0, 3, 0, 0, 3, 1, 3, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 3, 1, 1, 2, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 0, 3, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJeRCGfHNVLn"
      },
      "source": [
        "### 3-4. Hyperparameter Tuning(Optional)\n",
        "* Manual Search, Grid search, Bayesian Optimization, TPE...\n",
        "> * [grid search tutorial sklearn](https://scikit-learn.org/stable/modules/grid_search.html)\n",
        "> * [optuna tutorial](https://optuna.org/#code_examples)\n",
        "> * [ray-tune tutorial](https://docs.ray.io/en/latest/tune/examples/tune-sklearn.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0olXGe7NVLn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Machine Learning(N-grams, 강사님)"
      ],
      "metadata": {
        "id": "E1tyaaaUgPye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 : SGDClassifier with TF-IDF"
      ],
      "metadata": {
        "id": "rAiExfZSgY39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tfidf_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD4IedB2oZ7g",
        "outputId": "ec690e85-2798-4821-cfa7-d50dbebf8a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2779, 9917), (2779,))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "print(\"SGDClassifier(Linear SVM) with TF-IDF\")\n",
        "sgdClf = SGDClassifier(loss='hinge')\n",
        "sgdClf.fit(X = x_tfidf_train, y = y_train)\n",
        "y_pred = sgdClf.predict(x_tfidf_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "print(\"*\" * 100)\n",
        "print(\"Logistic Regression with TF-IDF\")\n",
        "sgdClf = SGDClassifier(loss='log')\n",
        "sgdClf.fit(X = x_tfidf_train, y= y_train)\n",
        "y_pred = sgdClf.predict(x_tfidf_val)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sueKx8wygXrt",
        "outputId": "eb5c35be-9e13-407b-f2de-af886a332fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGDClassifier(Linear SVM) with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       392\n",
            "           1       0.86      0.85      0.86       179\n",
            "           2       0.77      0.72      0.74       195\n",
            "           3       0.84      0.82      0.83       130\n",
            "           4       1.00      0.84      0.91        31\n",
            "\n",
            "    accuracy                           0.84       927\n",
            "   macro avg       0.86      0.82      0.84       927\n",
            "weighted avg       0.84      0.84      0.84       927\n",
            "\n",
            "****************************************************************************************************\n",
            "Logistic Regression with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       392\n",
            "           1       0.87      0.83      0.85       179\n",
            "           2       0.79      0.75      0.77       195\n",
            "           3       0.88      0.82      0.85       130\n",
            "           4       1.00      0.61      0.76        31\n",
            "\n",
            "    accuracy                           0.84       927\n",
            "   macro avg       0.88      0.79      0.82       927\n",
            "weighted avg       0.85      0.84      0.84       927\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 : SGDClassifier with Word2Vec"
      ],
      "metadata": {
        "id": "bPSwEd-EpGRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "xeZRwwGMs2wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SGDClassifier with Word2Vec\")\n",
        "w2v_sgd = SGDClassifier(loss='hinge')\n",
        "w2v_sgd.fit(x_w2v_train, y_train)\n",
        "y_pred = w2v_sgd.predict(x_w2v_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "print(\"*\" * 100)\n",
        "print(\"GBM with Word2Vec\")\n",
        "w2v_gd = GradientBoostingClassifier()\n",
        "w2v_gd.fit(x_w2v_train, y_train)\n",
        "y_pred = w2v_gd.predict(x_w2v_val)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noLxhJxEgX1D",
        "outputId": "d95f30e2-4b41-4270-e502-574b7b25a605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGDClassifier with Word2Vec\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.96      0.72       392\n",
            "           1       0.73      0.27      0.39       179\n",
            "           2       0.60      0.29      0.39       195\n",
            "           3       0.78      0.51      0.61       130\n",
            "           4       0.59      0.52      0.55        31\n",
            "\n",
            "    accuracy                           0.61       927\n",
            "   macro avg       0.65      0.51      0.53       927\n",
            "weighted avg       0.64      0.61      0.57       927\n",
            "\n",
            "****************************************************************************************************\n",
            "GBM with Word2Vec\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.81      0.77       392\n",
            "           1       0.58      0.54      0.56       179\n",
            "           2       0.61      0.53      0.57       195\n",
            "           3       0.59      0.61      0.60       130\n",
            "           4       0.32      0.23      0.26        31\n",
            "\n",
            "    accuracy                           0.65       927\n",
            "   macro avg       0.57      0.54      0.55       927\n",
            "weighted avg       0.64      0.65      0.65       927\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 : SVM, GBM, ML with Word2Vec(pre_trained)"
      ],
      "metadata": {
        "id": "pdC6J4oeqiD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "fC4q9ONes3l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SGDClassifier with Word2Vec\")\n",
        "w2v_sgd = SGDClassifier(loss='hinge')\n",
        "w2v_sgd.fit(x_pr_train, y_train)\n",
        "y_pred = w2v_sgd.predict(x_pr_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "print(\"*\" * 100)\n",
        "print(\"GBM with Word2Vec\")\n",
        "w2v_gd = GradientBoostingClassifier()\n",
        "w2v_gd.fit(x_pr_train, y_train)\n",
        "y_pred = w2v_gd.predict(x_pr_val)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx7laRJFqhcu",
        "outputId": "2b1c637c-7ff9-4daa-c3a0-28992c97345c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGDClassifier with Word2Vec\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.80      0.79       392\n",
            "           1       0.65      0.65      0.65       179\n",
            "           2       0.63      0.74      0.68       195\n",
            "           3       0.79      0.62      0.69       130\n",
            "           4       1.00      0.35      0.52        31\n",
            "\n",
            "    accuracy                           0.72       927\n",
            "   macro avg       0.77      0.63      0.67       927\n",
            "weighted avg       0.73      0.72      0.72       927\n",
            "\n",
            "****************************************************************************************************\n",
            "GBM with Word2Vec\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.85      0.79       392\n",
            "           1       0.62      0.58      0.60       179\n",
            "           2       0.71      0.59      0.65       195\n",
            "           3       0.66      0.70      0.68       130\n",
            "           4       1.00      0.19      0.32        31\n",
            "\n",
            "    accuracy                           0.70       927\n",
            "   macro avg       0.75      0.58      0.61       927\n",
            "weighted avg       0.71      0.70      0.69       927\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4 : Naive Bayes with TF-IDF"
      ],
      "metadata": {
        "id": "hUK57paRrBHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB, GaussianNB"
      ],
      "metadata": {
        "id": "Pr-OYrCRgYAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MultinomialNB with TF-IDF\")\n",
        "multi = MultinomialNB()\n",
        "multi.fit(x_tfidf_train, y_train)\n",
        "y_pred = multi.predict(x_tfidf_val)\n",
        "print(classification_report(y_val, y_pred, zero_division=0))\n",
        "\n",
        "print(\"*\" * 100)\n",
        "print(\"ComplementNB with TF-IDF\")\n",
        "comple = ComplementNB()\n",
        "comple.fit(x_tfidf_train, y_train)\n",
        "y_pred = comple.predict(x_tfidf_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "print(\"*\" * 100)\n",
        "print(\"BernoulliNB with TF-IDF\")\n",
        "bernoulli = BernoulliNB()\n",
        "bernoulli.fit(x_tfidf_train, y_train)\n",
        "y_pred = bernoulli.predict(x_tfidf_val)\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "print(\"*\" * 100)\n",
        "print(\"GaussianNB with TF-IDF\")\n",
        "gauss = GaussianNB()\n",
        "gauss.fit(x_tfidf_train.toarray(), y_train)\n",
        "y_pred = gauss.predict(x_tfidf_val.toarray())\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNP6fyEWgX5k",
        "outputId": "9955fff9-2ae8-49af-dec3-cbf40b8a3e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      1.00      0.69       392\n",
            "           1       0.91      0.39      0.54       179\n",
            "           2       0.96      0.24      0.39       195\n",
            "           3       0.92      0.45      0.60       130\n",
            "           4       0.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.61       927\n",
            "   macro avg       0.66      0.41      0.44       927\n",
            "weighted avg       0.73      0.61      0.56       927\n",
            "\n",
            "****************************************************************************************************\n",
            "ComplementNB with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.94      0.88       392\n",
            "           1       0.91      0.79      0.85       179\n",
            "           2       0.83      0.71      0.76       195\n",
            "           3       0.85      0.90      0.88       130\n",
            "           4       0.94      0.55      0.69        31\n",
            "\n",
            "    accuracy                           0.85       927\n",
            "   macro avg       0.87      0.78      0.81       927\n",
            "weighted avg       0.85      0.85      0.84       927\n",
            "\n",
            "****************************************************************************************************\n",
            "BernoulliNB with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.81      0.85       392\n",
            "           1       0.79      0.82      0.80       179\n",
            "           2       0.73      0.81      0.77       195\n",
            "           3       0.70      0.92      0.79       130\n",
            "           4       0.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.80       927\n",
            "   macro avg       0.62      0.67      0.64       927\n",
            "weighted avg       0.78      0.80      0.79       927\n",
            "\n",
            "****************************************************************************************************\n",
            "GaussianNB with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.84      0.78       392\n",
            "           1       0.78      0.76      0.77       179\n",
            "           2       0.65      0.57      0.61       195\n",
            "           3       0.75      0.65      0.70       130\n",
            "           4       0.62      0.16      0.26        31\n",
            "\n",
            "    accuracy                           0.72       927\n",
            "   macro avg       0.70      0.60      0.62       927\n",
            "weighted avg       0.72      0.72      0.71       927\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "TgDmxWxAtBbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MLPClassifier with TF-IDF\")\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(x_tfidf_train, y_train)\n",
        "y_pred = mlp.predict(x_tfidf_val)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmb9WA7r33-7",
        "outputId": "184aace6-fa9f-4180-c01f-bb13af9fa7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPClassifier with TF-IDF\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       392\n",
            "           1       0.85      0.86      0.85       179\n",
            "           2       0.79      0.73      0.76       195\n",
            "           3       0.88      0.84      0.86       130\n",
            "           4       0.94      0.55      0.69        31\n",
            "\n",
            "    accuracy                           0.84       927\n",
            "   macro avg       0.86      0.78      0.81       927\n",
            "weighted avg       0.84      0.84      0.84       927\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6apQWHoNVLn"
      },
      "source": [
        "## 4. Deep Learning(Sequence)\n",
        "* Sequence로 전처리한 데이터를 이용하여 DNN, 1-D CNN, LSTM 등 3가지 이상의 deep learning 모델 학습 및 성능 분석\n",
        "> * [Google Tutorial](https://developers.google.com/machine-learning/guides/text-classification)\n",
        "> * [Tensorflow Tutorial](https://www.tensorflow.org/tutorials/keras/text_classification)\n",
        "> * [Keras-tutorial](https://keras.io/examples/nlp/text_classification_from_scratch/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALa7qGD4NVLn"
      },
      "source": [
        "### 4-1. DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5LV2tyANVLn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_last_layer_units_and_activation(num_classes):\n",
        "    \"\"\"Gets the # units and activation function for the last network layer.\n",
        "\n",
        "    # Arguments\n",
        "        num_classes: int, number of classes.\n",
        "\n",
        "    # Returns\n",
        "        units, activation values.\n",
        "    \"\"\"\n",
        "    if num_classes == 2:\n",
        "        activation = 'sigmoid'\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "        units = num_classes\n",
        "    return units, activation"
      ],
      "metadata": {
        "id": "ix44MNyM5ltC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
        "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        An MLP model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
        "\n",
        "    for _ in range(layers-1):\n",
        "        model.add(Dense(units=units, activation='swish'))\n",
        "        # model.add(BatchNormalization())\n",
        "        # model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(units=op_units, activation=op_activation))\n",
        "    return model"
      ],
      "metadata": {
        "id": "GM8YZkov4Mg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 모델 파라미터 설정\n",
        "layers = 8  # Dense 레이어 수\n",
        "units = 1024  # 각 Dense 레이어의 뉴런 수\n",
        "dropout_rate = 0.0  # Dropout 레이어의 dropout 비율\n",
        "input_shape = (x_mor_sequence_train.shape[1],)  # 입력 데이터의 형태\n",
        "num_classes = 5  # 출력 클래스의 수\n",
        "\n",
        "# MLP 모델 생성\n",
        "model = mlp_model(layers, units, dropout_rate, input_shape, num_classes)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # 옵티마이저 설정 (Adam 사용)\n",
        "    loss='sparse_categorical_crossentropy',  # 손실 함수\n",
        "    metrics=['accuracy']  # 평가 지표 (정확도)\n",
        ")\n",
        "\n",
        "# 모델 요약 정보 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOnHxLO643vR",
        "outputId": "fcd0afb1-aa1a-4c10-c83c-cee9ba0d79e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_2 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1024)              513024    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 5)                 5125      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6815749 (26.00 MB)\n",
            "Trainable params: 6815749 (26.00 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=1, restore_best_weights=True)\n",
        "history = model.fit(x_mor_sequence_train, y_train, verbose=1, validation_split=0.1, epochs=50) # callbacks=es"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp_0liyk44Bk",
        "outputId": "7d379ceb-c373-443f-862c-6caaa5a15c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "79/79 [==============================] - 4s 8ms/step - loss: 16.6918 - accuracy: 0.3543 - val_loss: 1.4906 - val_accuracy: 0.3993\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3600 - accuracy: 0.4194 - val_loss: 1.5223 - val_accuracy: 0.3633\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2397 - accuracy: 0.4730 - val_loss: 1.6109 - val_accuracy: 0.2770\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1822 - accuracy: 0.4986 - val_loss: 1.5729 - val_accuracy: 0.2770\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.5954 - val_loss: 1.6224 - val_accuracy: 0.3237\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8956 - accuracy: 0.6413 - val_loss: 2.3341 - val_accuracy: 0.3237\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9176 - accuracy: 0.6709 - val_loss: 2.1566 - val_accuracy: 0.2338\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8084 - accuracy: 0.7077 - val_loss: 2.1858 - val_accuracy: 0.3345\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5792 - accuracy: 0.7861 - val_loss: 2.5857 - val_accuracy: 0.3345\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.8277 - val_loss: 3.1604 - val_accuracy: 0.3022\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8345 - val_loss: 2.8338 - val_accuracy: 0.3309\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.8413 - val_loss: 3.4758 - val_accuracy: 0.3201\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8701 - val_loss: 3.1088 - val_accuracy: 0.3129\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2912 - accuracy: 0.9060 - val_loss: 3.2163 - val_accuracy: 0.3094\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8860 - val_loss: 3.3582 - val_accuracy: 0.2986\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9376 - val_loss: 3.5199 - val_accuracy: 0.3129\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9288 - val_loss: 3.3386 - val_accuracy: 0.2482\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2274 - accuracy: 0.9280 - val_loss: 2.9230 - val_accuracy: 0.3201\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2576 - accuracy: 0.9156 - val_loss: 3.9245 - val_accuracy: 0.3094\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9412 - val_loss: 3.1134 - val_accuracy: 0.2914\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.9428 - val_loss: 4.2283 - val_accuracy: 0.2986\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.2483 - accuracy: 0.9264 - val_loss: 3.7720 - val_accuracy: 0.3417\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1341 - accuracy: 0.9588 - val_loss: 3.6758 - val_accuracy: 0.3094\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1473 - accuracy: 0.9616 - val_loss: 3.4022 - val_accuracy: 0.2950\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1274 - accuracy: 0.9612 - val_loss: 3.7954 - val_accuracy: 0.2950\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1186 - accuracy: 0.9652 - val_loss: 4.3091 - val_accuracy: 0.2698\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.1444 - accuracy: 0.9608 - val_loss: 3.9476 - val_accuracy: 0.2986\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.1463 - accuracy: 0.9600 - val_loss: 5.9932 - val_accuracy: 0.3381\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.1601 - accuracy: 0.9560 - val_loss: 3.7998 - val_accuracy: 0.3381\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2146 - accuracy: 0.9388 - val_loss: 3.4695 - val_accuracy: 0.2878\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2924 - accuracy: 0.9156 - val_loss: 3.3624 - val_accuracy: 0.3129\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2754 - accuracy: 0.9192 - val_loss: 4.0505 - val_accuracy: 0.2986\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9272 - val_loss: 3.3473 - val_accuracy: 0.3381\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.9280 - val_loss: 3.4681 - val_accuracy: 0.3094\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5403 - accuracy: 0.8940 - val_loss: 4.2286 - val_accuracy: 0.2518\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0972 - accuracy: 0.8848 - val_loss: 3.7745 - val_accuracy: 0.3417\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9583 - accuracy: 0.8485 - val_loss: 4.6687 - val_accuracy: 0.3273\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1953 - accuracy: 0.8764 - val_loss: 3.5565 - val_accuracy: 0.2014\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5071 - accuracy: 0.7921 - val_loss: 3.6125 - val_accuracy: 0.3165\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.0752 - accuracy: 0.7673 - val_loss: 4.2305 - val_accuracy: 0.3597\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6232 - accuracy: 0.7749 - val_loss: 2.7740 - val_accuracy: 0.2374\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1086 - accuracy: 0.8477 - val_loss: 3.0559 - val_accuracy: 0.3094\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2288 - accuracy: 0.7117 - val_loss: 7.5706 - val_accuracy: 0.2518\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.8556 - accuracy: 0.6805 - val_loss: 3.2605 - val_accuracy: 0.3705\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 13.1794 - accuracy: 0.7561 - val_loss: 10.9870 - val_accuracy: 0.3237\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 3.9458 - accuracy: 0.4746 - val_loss: 2.0288 - val_accuracy: 0.3381\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9092 - accuracy: 0.7117 - val_loss: 4.2563 - val_accuracy: 0.3489\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7465 - accuracy: 0.8553 - val_loss: 4.3877 - val_accuracy: 0.3094\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.9188 - val_loss: 4.2500 - val_accuracy: 0.3237\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9203 - accuracy: 0.9112 - val_loss: 10.6865 - val_accuracy: 0.3237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_mor_sequence_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1_OnS026A-R",
        "outputId": "37fde3eb-c035-46d0-a285-8ac3db2bfa86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 3ms/step - loss: 8.3964 - accuracy: 0.3916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.396431922912598, 0.3915857672691345]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 모델 파라미터 설정\n",
        "layers = 8  # Dense 레이어 수\n",
        "units = 1024  # 각 Dense 레이어의 뉴런 수\n",
        "dropout_rate = 0.0  # Dropout 레이어의 dropout 비율\n",
        "input_shape = (x_pr_train.shape[1],)  # 입력 데이터의 형태\n",
        "num_classes = 5  # 출력 클래스의 수\n",
        "\n",
        "# MLP 모델 생성\n",
        "model = mlp_model(layers, units, dropout_rate, input_shape, num_classes)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # 옵티마이저 설정 (Adam 사용)\n",
        "    loss='sparse_categorical_crossentropy',  # 손실 함수\n",
        "    metrics=['accuracy']  # 평가 지표 (정확도)\n",
        ")\n",
        "\n",
        "# 모델 요약 정보 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4yXktgnxQp5",
        "outputId": "9872a73c-e4ce-4792-d567-ff0881c82653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1024)              103424    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 5)                 5125      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6406149 (24.44 MB)\n",
            "Trainable params: 6406149 (24.44 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=1, restore_best_weights=True)\n",
        "history = model.fit(x_pr_train, y_train, verbose=1, callbacks=es, validation_split=0.1, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf_hcJRXw2tG",
        "outputId": "a5b15b14-f1b8-4175-cdd3-105d4e47541c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.6893 - accuracy: 0.7337 - val_loss: 1.0521 - val_accuracy: 0.5971\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7025 - accuracy: 0.7285 - val_loss: 0.7835 - val_accuracy: 0.6727\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6812 - accuracy: 0.7329 - val_loss: 0.7964 - val_accuracy: 0.6942\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6862 - accuracy: 0.7305 - val_loss: 0.8083 - val_accuracy: 0.7158\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.7597 - val_loss: 0.8473 - val_accuracy: 0.6978\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.7521 - val_loss: 0.8017 - val_accuracy: 0.6871\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.7593 - val_loss: 0.8045 - val_accuracy: 0.7194\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.7633 - val_loss: 0.8067 - val_accuracy: 0.7194\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.7537 - val_loss: 0.7423 - val_accuracy: 0.7122\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6252 - accuracy: 0.7649 - val_loss: 0.7947 - val_accuracy: 0.7014\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6276 - accuracy: 0.7609 - val_loss: 0.7473 - val_accuracy: 0.7302\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6076 - accuracy: 0.7789 - val_loss: 0.7276 - val_accuracy: 0.7158\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.7613 - val_loss: 0.8014 - val_accuracy: 0.6906\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.7421 - val_loss: 0.8998 - val_accuracy: 0.6583\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.6118 - accuracy: 0.7649 - val_loss: 0.7741 - val_accuracy: 0.7374\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.6259 - accuracy: 0.7569 - val_loss: 0.7640 - val_accuracy: 0.7050\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.6016 - accuracy: 0.7641 - val_loss: 0.7559 - val_accuracy: 0.7338\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5896 - accuracy: 0.7629 - val_loss: 0.7748 - val_accuracy: 0.7122\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5885 - accuracy: 0.7657 - val_loss: 0.8798 - val_accuracy: 0.7014\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5627 - accuracy: 0.7797 - val_loss: 0.8469 - val_accuracy: 0.7122\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5967 - accuracy: 0.7621 - val_loss: 0.8514 - val_accuracy: 0.6835\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5797 - accuracy: 0.7769 - val_loss: 0.8087 - val_accuracy: 0.7122\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.5866 - accuracy: 0.7653 - val_loss: 0.9234 - val_accuracy: 0.6511\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7817 - val_loss: 0.8252 - val_accuracy: 0.7122\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7869 - val_loss: 0.8072 - val_accuracy: 0.7014\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7797 - val_loss: 0.9018 - val_accuracy: 0.6871\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7753 - val_loss: 0.7807 - val_accuracy: 0.7230\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.5709 - accuracy: 0.7729 - val_loss: 0.8152 - val_accuracy: 0.7050\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7451 - accuracy: 0.7253 - val_loss: 0.7846 - val_accuracy: 0.7194\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0372 - accuracy: 0.6042 - val_loss: 1.1657 - val_accuracy: 0.5036\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9055 - accuracy: 0.6437 - val_loss: 0.9680 - val_accuracy: 0.5719\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8293 - accuracy: 0.6729 - val_loss: 1.0156 - val_accuracy: 0.5791\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7452 - accuracy: 0.7149 - val_loss: 0.8234 - val_accuracy: 0.6403\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7084 - accuracy: 0.7265 - val_loss: 0.7945 - val_accuracy: 0.7014\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.7493 - val_loss: 0.7387 - val_accuracy: 0.7050\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.7337 - val_loss: 0.7550 - val_accuracy: 0.7158\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.7489 - val_loss: 0.7438 - val_accuracy: 0.6942\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6609 - accuracy: 0.7473 - val_loss: 0.7616 - val_accuracy: 0.6871\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.7477 - val_loss: 0.7392 - val_accuracy: 0.7158\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.7453 - val_loss: 0.7931 - val_accuracy: 0.6799\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.7557 - val_loss: 0.8643 - val_accuracy: 0.6763\n",
            "Epoch 42/100\n",
            "72/79 [==========================>...] - ETA: 0s - loss: 0.6163 - accuracy: 0.7587Restoring model weights from the end of the best epoch: 12.\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.6274 - accuracy: 0.7569 - val_loss: 0.7435 - val_accuracy: 0.7194\n",
            "Epoch 42: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_pr_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH3hbdtVw_z4",
        "outputId": "19ebbe02-7793-4345-e589-f8a733c7e771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.7422\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.710953414440155, 0.7421790957450867]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgLPjRH66hYR",
        "outputId": "214fd12c-0d46-4612-f7fb-4feba3c5d1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.8238525e-01, 2.3671661e-01, 2.1358614e-01, 1.6615693e-01,\n",
              "        1.1550167e-03],\n",
              "       [9.9999940e-01, 7.8755406e-08, 1.1236010e-07, 3.3641663e-07,\n",
              "        2.5142522e-19],\n",
              "       [2.7679157e-01, 1.9682245e-01, 1.8758838e-01, 2.0367938e-01,\n",
              "        1.3511825e-01],\n",
              "       ...,\n",
              "       [2.8777069e-01, 2.0396349e-01, 1.9230278e-01, 2.0617019e-01,\n",
              "        1.0979281e-01],\n",
              "       [2.7679157e-01, 1.9682245e-01, 1.8758838e-01, 2.0367938e-01,\n",
              "        1.3511825e-01],\n",
              "       [2.9756188e-01, 2.1021362e-01, 1.9605401e-01, 2.0753504e-01,\n",
              "        8.8635437e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTAG6hGO6BDw",
        "outputId": "6d12d241-8ead-4000-de4e-f74de1b47ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.89      0.71       392\n",
            "           1       0.00      0.00      0.00       179\n",
            "           2       0.27      0.47      0.34       195\n",
            "           3       0.00      0.00      0.00       130\n",
            "           4       0.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.47       927\n",
            "   macro avg       0.17      0.27      0.21       927\n",
            "weighted avg       0.31      0.47      0.37       927\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fznxLNLSNVLn"
      },
      "source": [
        "### 4-2. 1-D CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, Conv1D, MaxPool1D\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "x-NYVZ7UYpjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape 확인\n",
        "x_mor_sequence_train.shape"
      ],
      "metadata": {
        "id": "G7r7z5xYagbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ffff56-874e-4753-ac97-d3b9a8e22e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2779, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLqhX6rONVLn"
      },
      "outputs": [],
      "source": [
        "# # 1. 세션 클리어\n",
        "# clear_session()\n",
        "\n",
        "# # 2. 레이어 엮기\n",
        "# il = Input(shape=[x_mor_sequence_train.shape[1],])\n",
        "\n",
        "# hl = Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')(il)\n",
        "# hl = Conv1D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = MaxPool1D(pool_size=(2, 2), strides=(2, 2))(hl)\n",
        "# hl = BatchNormalization()(hl)\n",
        "# hl = Dropout(0.2)(hl)\n",
        "\n",
        "# hl = Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = Conv1D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(hl)\n",
        "# hl = BatchNormalization()(hl)\n",
        "# hl = Dropout(0.2)(hl)\n",
        "\n",
        "# hl = Conv1D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = Conv1D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = Conv1D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(hl)\n",
        "# hl = BatchNormalization()(hl)\n",
        "# hl = Dropout(0.2)(hl)\n",
        "\n",
        "# hl = Conv1D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = Conv1D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = Conv1D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')(hl)\n",
        "# hl = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(hl)\n",
        "# hl = BatchNormalization()(hl)\n",
        "# hl = Dropout(0.5)(hl)\n",
        "\n",
        "# hl = Flatten()(hl)\n",
        "\n",
        "# hl = Dense(1024, activation='relu')(hl)\n",
        "# hl = BatchNormalization()(hl)\n",
        "# hl = Dropout(0.3)(hl)\n",
        "\n",
        "# ol = Dense(5, activation='softmax')(hl)\n",
        "\n",
        "# # 3. 모델 선언\n",
        "# model = Model(il, ol)\n",
        "\n",
        "# # 4. 모델 컴파일\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, restore_best_weights=True)\n",
        "history = model.fit(x_mor_sequence_train, y_train, verbose=1, callbacks=es, validation_split=0.2, epochs=10)"
      ],
      "metadata": {
        "id": "bCHIpi_bYRX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_mor_sequence_val, y_val)\n",
        "y_pred = model.predict(x_mor_sequence_val)\n",
        "accuracy_score(y_val, y_pred)"
      ],
      "metadata": {
        "id": "ElASC6opYVeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-2-1 구글\n"
      ],
      "metadata": {
        "id": "3i1QQAtm900y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import SeparableConv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "\n",
        "def sepcnn_model(blocks,\n",
        "                 filters,\n",
        "                 kernel_size,\n",
        "                 embedding_dim,\n",
        "                 dropout_rate,\n",
        "                 pool_size,\n",
        "                 input_shape,\n",
        "                 num_classes,\n",
        "                 num_features,\n",
        "                 use_pretrained_embedding=False,\n",
        "                 is_embedding_trainable=False,\n",
        "                 embedding_matrix=None):\n",
        "    \"\"\"Creates an instance of a separable CNN model.\n",
        "\n",
        "    # Arguments\n",
        "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
        "        filters: int, output dimension of the layers.\n",
        "        kernel_size: int, length of the convolution window.\n",
        "        embedding_dim: int, dimension of the embedding vectors.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "        num_features: int, number of words (embedding input dimension).\n",
        "        use_pretrained_embedding: bool, true if pre-trained embedding is on.\n",
        "        is_embedding_trainable: bool, true if embedding layer is trainable.\n",
        "        embedding_matrix: dict, dictionary with embedding coefficients.\n",
        "\n",
        "    # Returns\n",
        "        A sepCNN model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Add embedding layer. If pre-trained embedding is used add weights to the\n",
        "    # embeddings layer and set trainable to input is_embedding_trainable flag.\n",
        "    if use_pretrained_embedding:\n",
        "        model.add(Embedding(input_dim=num_features,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=input_shape[0],\n",
        "                            weights=[embedding_matrix],\n",
        "                            trainable=is_embedding_trainable))\n",
        "    else:\n",
        "        model.add(Embedding(input_dim=num_features,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=input_shape[0]))\n",
        "\n",
        "    for _ in range(blocks-1):\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(MaxPooling1D(pool_size=pool_size))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(Dense(op_units, activation=op_activation))\n",
        "    return model"
      ],
      "metadata": {
        "id": "Xqerr7qNYYQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "max_features = x_mor_sequence_train.shape[1]  # Vocabulary size\n",
        "max_len = 500  # Maximum sequence length\n",
        "\n",
        "# Create the SepCNN model\n",
        "model = sepcnn_model(\n",
        "    blocks=3,\n",
        "    filters=256,\n",
        "    kernel_size=3,\n",
        "    embedding_dim=128,\n",
        "    dropout_rate=0.4,\n",
        "    pool_size=3,\n",
        "    input_shape=(max_len,),\n",
        "    num_classes=5,\n",
        "    num_features=max_features,\n",
        "    use_pretrained_embedding=False,\n",
        "    is_embedding_trainable=True\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "pT3Z1wHr-Muw",
        "outputId": "e635ec35-03af-4a06-cef6-846ba76b5713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4a629b76eb9a>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create the SepCNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m model = sepcnn_model(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-75bd765a5857>\u001b[0m in \u001b[0;36msepcnn_model\u001b[0;34m(blocks, filters, kernel_size, embedding_dim, dropout_rate, pool_size, input_shape, num_classes, num_features, use_pretrained_embedding, is_embedding_trainable, embedding_matrix)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mA\u001b[0m \u001b[0msepCNN\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mop_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_last_layer_units_and_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_get_last_layer_units_and_activation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 80\n",
        "batch_size = 32\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=1, restore_best_weights=True)\n",
        "# history = model.fit(x_mor_sequence_train, y_train, verbose=1, callbacks=es, validation_split=0.1, epochs=epochs)\n",
        "model.fit(x_mor_sequence_train, y_train, verbose=1, epochs=epochs, batch_size=batch_size, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olmi0sOBSmg5",
        "outputId": "90ca6c0c-a564-421e-a99e-3667179e007f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.8310 - accuracy: 0.6369 - val_loss: 1.2516 - val_accuracy: 0.5360\n",
            "Epoch 2/80\n",
            "79/79 [==============================] - 2s 29ms/step - loss: 0.8357 - accuracy: 0.6421 - val_loss: 1.1051 - val_accuracy: 0.5647\n",
            "Epoch 3/80\n",
            "79/79 [==============================] - 2s 29ms/step - loss: 0.8185 - accuracy: 0.6437 - val_loss: 1.1720 - val_accuracy: 0.5504\n",
            "Epoch 4/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.8053 - accuracy: 0.6549 - val_loss: 1.2536 - val_accuracy: 0.5468\n",
            "Epoch 5/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.7924 - accuracy: 0.6597 - val_loss: 1.5322 - val_accuracy: 0.4496\n",
            "Epoch 6/80\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.7821 - accuracy: 0.6573 - val_loss: 1.9151 - val_accuracy: 0.4173\n",
            "Epoch 7/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.7654 - accuracy: 0.6713 - val_loss: 1.8453 - val_accuracy: 0.4353\n",
            "Epoch 8/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.7975 - accuracy: 0.6613 - val_loss: 1.2676 - val_accuracy: 0.5360\n",
            "Epoch 9/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.7817 - accuracy: 0.6657 - val_loss: 2.5622 - val_accuracy: 0.3885\n",
            "Epoch 10/80\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.7368 - accuracy: 0.6889 - val_loss: 1.4556 - val_accuracy: 0.5072\n",
            "Epoch 11/80\n",
            "79/79 [==============================] - 3s 32ms/step - loss: 0.7502 - accuracy: 0.6837 - val_loss: 1.4064 - val_accuracy: 0.5216\n",
            "Epoch 12/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.7562 - accuracy: 0.6789 - val_loss: 2.2730 - val_accuracy: 0.4101\n",
            "Epoch 13/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.7541 - accuracy: 0.6813 - val_loss: 1.5933 - val_accuracy: 0.4964\n",
            "Epoch 14/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.7197 - accuracy: 0.6881 - val_loss: 1.3986 - val_accuracy: 0.5324\n",
            "Epoch 15/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.7392 - accuracy: 0.6897 - val_loss: 1.3841 - val_accuracy: 0.5468\n",
            "Epoch 16/80\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 0.7071 - accuracy: 0.7033 - val_loss: 2.1397 - val_accuracy: 0.4065\n",
            "Epoch 17/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.7324 - accuracy: 0.6965 - val_loss: 1.1881 - val_accuracy: 0.5360\n",
            "Epoch 18/80\n",
            "79/79 [==============================] - 3s 37ms/step - loss: 0.7069 - accuracy: 0.7001 - val_loss: 1.3268 - val_accuracy: 0.5540\n",
            "Epoch 19/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.6829 - accuracy: 0.7209 - val_loss: 1.6901 - val_accuracy: 0.5144\n",
            "Epoch 20/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.6809 - accuracy: 0.7121 - val_loss: 3.1131 - val_accuracy: 0.3885\n",
            "Epoch 21/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.6763 - accuracy: 0.7213 - val_loss: 1.8024 - val_accuracy: 0.4388\n",
            "Epoch 22/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.6366 - accuracy: 0.7357 - val_loss: 1.9624 - val_accuracy: 0.5288\n",
            "Epoch 23/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.6375 - accuracy: 0.7449 - val_loss: 3.5132 - val_accuracy: 0.3993\n",
            "Epoch 24/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.6265 - accuracy: 0.7465 - val_loss: 4.3689 - val_accuracy: 0.3741\n",
            "Epoch 25/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.6089 - accuracy: 0.7593 - val_loss: 1.2351 - val_accuracy: 0.5504\n",
            "Epoch 26/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.5959 - accuracy: 0.7593 - val_loss: 4.5315 - val_accuracy: 0.3777\n",
            "Epoch 27/80\n",
            "79/79 [==============================] - 2s 31ms/step - loss: 0.5652 - accuracy: 0.7673 - val_loss: 1.4605 - val_accuracy: 0.5755\n",
            "Epoch 28/80\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.5420 - accuracy: 0.7733 - val_loss: 1.4475 - val_accuracy: 0.5683\n",
            "Epoch 29/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.5446 - accuracy: 0.7813 - val_loss: 1.1889 - val_accuracy: 0.6259\n",
            "Epoch 30/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.5172 - accuracy: 0.7997 - val_loss: 1.4984 - val_accuracy: 0.5683\n",
            "Epoch 31/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.4865 - accuracy: 0.8053 - val_loss: 1.4840 - val_accuracy: 0.5863\n",
            "Epoch 32/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.4828 - accuracy: 0.8121 - val_loss: 6.6766 - val_accuracy: 0.4137\n",
            "Epoch 33/80\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 0.4665 - accuracy: 0.8205 - val_loss: 1.4183 - val_accuracy: 0.6079\n",
            "Epoch 34/80\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.4638 - accuracy: 0.8165 - val_loss: 1.4276 - val_accuracy: 0.6223\n",
            "Epoch 35/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.4205 - accuracy: 0.8373 - val_loss: 1.6621 - val_accuracy: 0.6223\n",
            "Epoch 36/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.4035 - accuracy: 0.8413 - val_loss: 2.0512 - val_accuracy: 0.5791\n",
            "Epoch 37/80\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.4690 - accuracy: 0.8253 - val_loss: 1.3729 - val_accuracy: 0.6151\n",
            "Epoch 38/80\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.4010 - accuracy: 0.8357 - val_loss: 1.4025 - val_accuracy: 0.6223\n",
            "Epoch 39/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.4098 - accuracy: 0.8425 - val_loss: 1.6095 - val_accuracy: 0.6115\n",
            "Epoch 40/80\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.3823 - accuracy: 0.8593 - val_loss: 4.1808 - val_accuracy: 0.4676\n",
            "Epoch 41/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.3526 - accuracy: 0.8625 - val_loss: 1.6243 - val_accuracy: 0.6295\n",
            "Epoch 42/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.4390 - accuracy: 0.8393 - val_loss: 2.0432 - val_accuracy: 0.6187\n",
            "Epoch 43/80\n",
            "79/79 [==============================] - 2s 30ms/step - loss: 0.3386 - accuracy: 0.8725 - val_loss: 2.2260 - val_accuracy: 0.5827\n",
            "Epoch 44/80\n",
            "79/79 [==============================] - 2s 29ms/step - loss: 0.3481 - accuracy: 0.8649 - val_loss: 1.6473 - val_accuracy: 0.6151\n",
            "Epoch 45/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.3250 - accuracy: 0.8772 - val_loss: 2.9181 - val_accuracy: 0.5683\n",
            "Epoch 46/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.2906 - accuracy: 0.8864 - val_loss: 1.5117 - val_accuracy: 0.6619\n",
            "Epoch 47/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.3564 - accuracy: 0.8665 - val_loss: 1.6311 - val_accuracy: 0.6151\n",
            "Epoch 48/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.2839 - accuracy: 0.8888 - val_loss: 2.0417 - val_accuracy: 0.5863\n",
            "Epoch 49/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.2809 - accuracy: 0.8940 - val_loss: 1.5082 - val_accuracy: 0.6295\n",
            "Epoch 50/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.2731 - accuracy: 0.8968 - val_loss: 2.6455 - val_accuracy: 0.5576\n",
            "Epoch 51/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.2522 - accuracy: 0.9044 - val_loss: 1.9831 - val_accuracy: 0.6511\n",
            "Epoch 52/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.2422 - accuracy: 0.9108 - val_loss: 1.7172 - val_accuracy: 0.6259\n",
            "Epoch 53/80\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.2208 - accuracy: 0.9128 - val_loss: 1.9252 - val_accuracy: 0.6223\n",
            "Epoch 54/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.2948 - accuracy: 0.8996 - val_loss: 1.9576 - val_accuracy: 0.6439\n",
            "Epoch 55/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.2771 - accuracy: 0.9020 - val_loss: 1.5328 - val_accuracy: 0.5863\n",
            "Epoch 56/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.2030 - accuracy: 0.9236 - val_loss: 2.1546 - val_accuracy: 0.6799\n",
            "Epoch 57/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.2080 - accuracy: 0.9208 - val_loss: 1.8837 - val_accuracy: 0.6727\n",
            "Epoch 58/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.2355 - accuracy: 0.9180 - val_loss: 1.8504 - val_accuracy: 0.6619\n",
            "Epoch 59/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.1751 - accuracy: 0.9320 - val_loss: 2.4042 - val_accuracy: 0.6367\n",
            "Epoch 60/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.1744 - accuracy: 0.9396 - val_loss: 2.9328 - val_accuracy: 0.6187\n",
            "Epoch 61/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.1730 - accuracy: 0.9412 - val_loss: 3.2733 - val_accuracy: 0.6367\n",
            "Epoch 62/80\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.1738 - accuracy: 0.9380 - val_loss: 1.9137 - val_accuracy: 0.6691\n",
            "Epoch 63/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.1682 - accuracy: 0.9416 - val_loss: 2.2091 - val_accuracy: 0.6691\n",
            "Epoch 64/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.1372 - accuracy: 0.9548 - val_loss: 1.8674 - val_accuracy: 0.6655\n",
            "Epoch 65/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1404 - accuracy: 0.9484 - val_loss: 2.0177 - val_accuracy: 0.6691\n",
            "Epoch 66/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.1561 - accuracy: 0.9496 - val_loss: 1.9104 - val_accuracy: 0.6691\n",
            "Epoch 67/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1590 - accuracy: 0.9480 - val_loss: 4.0958 - val_accuracy: 0.5396\n",
            "Epoch 68/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.1560 - accuracy: 0.9480 - val_loss: 5.9710 - val_accuracy: 0.5072\n",
            "Epoch 69/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.1199 - accuracy: 0.9600 - val_loss: 3.0624 - val_accuracy: 0.6043\n",
            "Epoch 70/80\n",
            "79/79 [==============================] - 2s 29ms/step - loss: 0.1420 - accuracy: 0.9460 - val_loss: 10.6108 - val_accuracy: 0.4460\n",
            "Epoch 71/80\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 0.1214 - accuracy: 0.9596 - val_loss: 6.5224 - val_accuracy: 0.4964\n",
            "Epoch 72/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.1372 - accuracy: 0.9548 - val_loss: 2.4104 - val_accuracy: 0.6942\n",
            "Epoch 73/80\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.1825 - accuracy: 0.9416 - val_loss: 1.7636 - val_accuracy: 0.6475\n",
            "Epoch 74/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.1322 - accuracy: 0.9588 - val_loss: 2.0950 - val_accuracy: 0.7014\n",
            "Epoch 75/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1038 - accuracy: 0.9628 - val_loss: 2.0650 - val_accuracy: 0.6799\n",
            "Epoch 76/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.1034 - accuracy: 0.9676 - val_loss: 2.0942 - val_accuracy: 0.7122\n",
            "Epoch 77/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.1205 - accuracy: 0.9592 - val_loss: 2.6504 - val_accuracy: 0.7014\n",
            "Epoch 78/80\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.1497 - accuracy: 0.9560 - val_loss: 1.9359 - val_accuracy: 0.6403\n",
            "Epoch 79/80\n",
            "79/79 [==============================] - 2s 29ms/step - loss: 0.1299 - accuracy: 0.9576 - val_loss: 2.3279 - val_accuracy: 0.6978\n",
            "Epoch 80/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.1204 - accuracy: 0.9616 - val_loss: 2.3486 - val_accuracy: 0.6727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x785640386680>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(x_mor_sequence_val)\n",
        "y_pred = tf.argmax(y_pred, axis=1).numpy()\n",
        "# y_val = tf.argmax(y_val, axis=1).numpy()\n",
        "report = classification_report(y_val, y_pred)\n",
        "model.evaluate(x_mor_sequence_val, y_val)\n",
        "print(report)\n",
        "print(\"accaurcy :\", accuracy_score(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlW9RlDySmjO",
        "outputId": "1c9a8bd4-ac5e-4690-e840-c4854f69ebfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 1s 14ms/step\n",
            "17/29 [================>.............] - ETA: 0s - loss: 1.0351 - accuracy: 0.5717"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 7ms/step - loss: 1.0500 - accuracy: 0.5566\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.85      0.77       392\n",
            "           1       0.33      0.39      0.36       179\n",
            "           2       0.45      0.10      0.16       195\n",
            "           3       0.48      0.72      0.58       130\n",
            "           4       0.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.56       927\n",
            "   macro avg       0.39      0.41      0.37       927\n",
            "weighted avg       0.52      0.56      0.51       927\n",
            "\n",
            "accaurcy : 0.5566343042071198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkvMu8QANVLo"
      },
      "source": [
        "### 4-3. LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Y4xSo2_nNVLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1908848-9ddb-4d86-b056-e9c6dad9c99e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 500, 16)           8000      \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 500, 64)           20736     \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 500, 32)           3104      \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 500, 5)            165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32005 (125.02 KB)\n",
            "Trainable params: 32005 (125.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# LSTM 모델 정의\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=x_mor_sequence_train.shape[1], output_dim=16, input_length=x_mor_sequence_train.shape[1]))\n",
        "model.add(LSTM(64, return_sequences=True))  # LSTM 레이어 추가\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
        "model.fit(x_mor_sequence_train, y_train, epochs=10, validation_split=0.1, callbacks=es)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eymz2NuWgnwL",
        "outputId": "0bda32ab-852e-40e3-fdbc-d436b0aa72c2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-656e3c480815>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mor_sequence_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n      ColabKernelApp.launch_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-62-656e3c480815>\", line 3, in <cell line: 3>\n      model.fit(x_mor_sequence_train, y_train, epochs=10, validation_split=0.1, callbacks=es)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1085, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1179, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 723, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/accuracy_metrics.py\", line 459, in sparse_categorical_accuracy\n      matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 968, in sparse_categorical_matches\n      matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_242257]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_mor_sequence_val, y_val)\n",
        "print(f\"val loss: {loss:.4f}, val accuracy: {accuracy:.4f}\")\n",
        "\n",
        "report = classification_report(y_val, y_pred)\n",
        "print(report)\n",
        "print(\"accaurcy :\", accuracy_score(y_val, y_pred))"
      ],
      "metadata": {
        "id": "RumBLsOUgpB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWCpxKLXNVLo"
      },
      "source": [
        "## 5. Using pre-trained model(Optional)\n",
        "* 한국어 pre-trained model로 fine tuning 및 성능 분석\n",
        "> * [BERT-tutorial](https://www.tensorflow.org/text/guide/bert_preprocessing_guide)\n",
        "> * [HuggingFace-Korean](https://huggingface.co/models?language=korean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dADfa7AnNVLo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle"
      ],
      "metadata": {
        "id": "sTNghuRZyJFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### deeplearning"
      ],
      "metadata": {
        "id": "4_jXs_LX26EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "8RK5dwCTyg3G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_last_layer_units_and_activation(num_classes):\n",
        "    \"\"\"Gets the # units and activation function for the last network layer.\n",
        "\n",
        "    # Arguments\n",
        "        num_classes: int, number of classes.\n",
        "\n",
        "    # Returns\n",
        "        units, activation values.\n",
        "    \"\"\"\n",
        "    if num_classes == 2:\n",
        "        activation = 'sigmoid'\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "        units = num_classes\n",
        "    return units, activation"
      ],
      "metadata": {
        "id": "B7FrGW8PyL_m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
        "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        An MLP model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
        "\n",
        "    for _ in range(layers-1):\n",
        "        model.add(Dense(units=units, activation='swish'))\n",
        "        # model.add(BatchNormalization())\n",
        "        # model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(units=op_units, activation=op_activation))\n",
        "    return model"
      ],
      "metadata": {
        "id": "Vvb5Buq00eSN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 모델 파라미터 설정\n",
        "layers = 8  # Dense 레이어 수\n",
        "units = 1024  # 각 Dense 레이어의 뉴런 수\n",
        "dropout_rate = 0.1  # Dropout 레이어의 dropout 비율\n",
        "input_shape = (x_pr_train.shape[1],)  # 입력 데이터의 형태\n",
        "num_classes = 5  # 출력 클래스의 수\n",
        "\n",
        "# MLP 모델 생성\n",
        "model = mlp_model(layers, units, dropout_rate, input_shape, num_classes)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # 옵티마이저 설정 (Adam 사용)\n",
        "    loss='sparse_categorical_crossentropy',  # 손실 함수\n",
        "    metrics=['accuracy']  # 평가 지표 (정확도)\n",
        ")\n",
        "\n",
        "# 모델 요약 정보 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8809LyD0Jxs",
        "outputId": "ac5f66c7-49e3-41cd-f65a-42d0790142c7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_17 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 1024)              103424    \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 5)                 5125      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6406149 (24.44 MB)\n",
            "Trainable params: 6406149 (24.44 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=1, restore_best_weights=True)\n",
        "history = model.fit(x_pr_train, y_train, verbose=1, callbacks=es, validation_split=0.1, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX8yqfB70J0b",
        "outputId": "197416fc-c125-4bd4-a27b-e7f516e45266"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 9s 23ms/step - loss: 1.8971 - accuracy: 0.4986 - val_loss: 1.6208 - val_accuracy: 0.3705\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 1.0431 - accuracy: 0.6074 - val_loss: 1.5427 - val_accuracy: 0.3705\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.9612 - accuracy: 0.6277 - val_loss: 1.8066 - val_accuracy: 0.3705\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9297 - accuracy: 0.6465 - val_loss: 1.9428 - val_accuracy: 0.3705\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9368 - accuracy: 0.6397 - val_loss: 1.3729 - val_accuracy: 0.4137\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9157 - accuracy: 0.6377 - val_loss: 1.3088 - val_accuracy: 0.4245\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8940 - accuracy: 0.6533 - val_loss: 1.1339 - val_accuracy: 0.5576\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 0.8861 - accuracy: 0.6509 - val_loss: 1.0261 - val_accuracy: 0.5647\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8827 - accuracy: 0.6565 - val_loss: 1.0281 - val_accuracy: 0.6223\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9166 - accuracy: 0.6529 - val_loss: 0.7848 - val_accuracy: 0.7014\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8883 - accuracy: 0.6585 - val_loss: 1.1138 - val_accuracy: 0.6727\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8819 - accuracy: 0.6633 - val_loss: 0.9343 - val_accuracy: 0.6547\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.8683 - accuracy: 0.6633 - val_loss: 0.8538 - val_accuracy: 0.7014\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 0.8466 - accuracy: 0.6733 - val_loss: 0.7590 - val_accuracy: 0.7302\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.8468 - accuracy: 0.6661 - val_loss: 0.9312 - val_accuracy: 0.5827\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.8496 - accuracy: 0.6793 - val_loss: 0.9160 - val_accuracy: 0.6511\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 0.8406 - accuracy: 0.6629 - val_loss: 0.8454 - val_accuracy: 0.6978\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8148 - accuracy: 0.6849 - val_loss: 0.7953 - val_accuracy: 0.7086\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8466 - accuracy: 0.6657 - val_loss: 0.7943 - val_accuracy: 0.7086\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.8394 - accuracy: 0.6729 - val_loss: 0.7930 - val_accuracy: 0.7302\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.8356 - accuracy: 0.6689 - val_loss: 0.8251 - val_accuracy: 0.6942\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8640 - accuracy: 0.6649 - val_loss: 1.7028 - val_accuracy: 0.6906\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.8520 - accuracy: 0.6705 - val_loss: 0.9765 - val_accuracy: 0.6367\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8370 - accuracy: 0.6697 - val_loss: 0.8150 - val_accuracy: 0.7086\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8303 - accuracy: 0.6893 - val_loss: 0.8911 - val_accuracy: 0.6547\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.8664 - accuracy: 0.6665 - val_loss: 0.8737 - val_accuracy: 0.6978\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8360 - accuracy: 0.6697 - val_loss: 0.8929 - val_accuracy: 0.6655\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 0.8102 - accuracy: 0.6885 - val_loss: 0.8659 - val_accuracy: 0.6619\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.8159 - accuracy: 0.6973 - val_loss: 0.8636 - val_accuracy: 0.6583\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.7849 - accuracy: 0.6949 - val_loss: 0.7873 - val_accuracy: 0.7086\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 0.8396 - accuracy: 0.6741 - val_loss: 0.9579 - val_accuracy: 0.6763\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.8190 - accuracy: 0.6805 - val_loss: 0.7597 - val_accuracy: 0.7230\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9226 - accuracy: 0.6577 - val_loss: 0.9882 - val_accuracy: 0.6151\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8295 - accuracy: 0.6673 - val_loss: 0.8677 - val_accuracy: 0.6727\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.8734 - accuracy: 0.6589 - val_loss: 0.9246 - val_accuracy: 0.5863\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.8407 - accuracy: 0.6845 - val_loss: 0.8431 - val_accuracy: 0.6691\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7944 - accuracy: 0.6921 - val_loss: 0.8114 - val_accuracy: 0.6727\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7906 - accuracy: 0.6997 - val_loss: 0.8210 - val_accuracy: 0.7014\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7931 - accuracy: 0.6969 - val_loss: 0.7939 - val_accuracy: 0.7122\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.7400 - accuracy: 0.7189 - val_loss: 0.8999 - val_accuracy: 0.6583\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7747 - accuracy: 0.7125 - val_loss: 0.7838 - val_accuracy: 0.7050\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.7961 - accuracy: 0.6977 - val_loss: 0.7600 - val_accuracy: 0.7158\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.7640 - accuracy: 0.7009 - val_loss: 0.8096 - val_accuracy: 0.6835\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.7951 - accuracy: 0.6997 - val_loss: 0.8081 - val_accuracy: 0.6835\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.7747 - accuracy: 0.6985 - val_loss: 0.8778 - val_accuracy: 0.6835\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.7650 - accuracy: 0.7141 - val_loss: 0.7966 - val_accuracy: 0.6906\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.7471 - accuracy: 0.7093 - val_loss: 0.8196 - val_accuracy: 0.6691\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.7408 - accuracy: 0.7085 - val_loss: 0.7736 - val_accuracy: 0.6906\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7946 - accuracy: 0.6829 - val_loss: 0.7533 - val_accuracy: 0.7302\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7264 - accuracy: 0.7229 - val_loss: 0.8079 - val_accuracy: 0.7194\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7350 - accuracy: 0.7225 - val_loss: 0.7617 - val_accuracy: 0.7050\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7423 - accuracy: 0.7149 - val_loss: 0.8177 - val_accuracy: 0.6871\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7320 - accuracy: 0.7201 - val_loss: 0.8502 - val_accuracy: 0.6691\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7749 - accuracy: 0.7161 - val_loss: 0.9099 - val_accuracy: 0.6259\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7343 - accuracy: 0.7201 - val_loss: 0.8053 - val_accuracy: 0.7086\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7187 - accuracy: 0.7277 - val_loss: 0.7970 - val_accuracy: 0.6906\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 0.7490 - accuracy: 0.7165 - val_loss: 0.7826 - val_accuracy: 0.6799\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.7125 - accuracy: 0.7253 - val_loss: 0.8604 - val_accuracy: 0.6871\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.7444 - accuracy: 0.7121 - val_loss: 0.7884 - val_accuracy: 0.7230\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.7067 - accuracy: 0.7401 - val_loss: 0.8060 - val_accuracy: 0.7050\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 1s 13ms/step - loss: 0.7100 - accuracy: 0.7157 - val_loss: 0.8473 - val_accuracy: 0.6511\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7103 - accuracy: 0.7273 - val_loss: 1.0242 - val_accuracy: 0.6691\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.7039 - accuracy: 0.7397 - val_loss: 0.8482 - val_accuracy: 0.6619\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.7218 - accuracy: 0.7249 - val_loss: 0.8620 - val_accuracy: 0.6978\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6969 - accuracy: 0.7353 - val_loss: 0.7970 - val_accuracy: 0.6978\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.8174 - accuracy: 0.6941 - val_loss: 0.8927 - val_accuracy: 0.6727\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7504 - accuracy: 0.7133 - val_loss: 0.8896 - val_accuracy: 0.6871\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7298 - accuracy: 0.7241 - val_loss: 0.8607 - val_accuracy: 0.6763\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7377 - accuracy: 0.7225 - val_loss: 0.7549 - val_accuracy: 0.7230\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6888 - accuracy: 0.7293 - val_loss: 1.0065 - val_accuracy: 0.6079\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7168 - accuracy: 0.7237 - val_loss: 0.8646 - val_accuracy: 0.6727\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 1s 15ms/step - loss: 0.6903 - accuracy: 0.7261 - val_loss: 0.7719 - val_accuracy: 0.7086\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.6913 - accuracy: 0.7345 - val_loss: 0.8903 - val_accuracy: 0.6835\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.6906 - accuracy: 0.7337 - val_loss: 0.9185 - val_accuracy: 0.6906\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 0.7951 - accuracy: 0.7061 - val_loss: 0.9196 - val_accuracy: 0.6655\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7444 - accuracy: 0.7229 - val_loss: 0.8948 - val_accuracy: 0.6475\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6618 - accuracy: 0.7461 - val_loss: 0.8133 - val_accuracy: 0.6942\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6979 - accuracy: 0.7313 - val_loss: 0.8657 - val_accuracy: 0.6403\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6429 - accuracy: 0.7581 - val_loss: 0.8460 - val_accuracy: 0.6799\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7150 - accuracy: 0.7333 - val_loss: 0.9661 - val_accuracy: 0.6655\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6541 - accuracy: 0.7513 - val_loss: 0.8132 - val_accuracy: 0.6799\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.6589 - accuracy: 0.7513 - val_loss: 0.8034 - val_accuracy: 0.6871\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.6447 - accuracy: 0.7533 - val_loss: 0.8839 - val_accuracy: 0.7014\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.6324 - accuracy: 0.7653 - val_loss: 0.8351 - val_accuracy: 0.7158\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6377 - accuracy: 0.7585 - val_loss: 0.9067 - val_accuracy: 0.6906\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 1s 14ms/step - loss: 0.6198 - accuracy: 0.7645 - val_loss: 0.9305 - val_accuracy: 0.6475\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.5886 - accuracy: 0.7765 - val_loss: 0.8617 - val_accuracy: 0.6835\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.6607 - accuracy: 0.7469 - val_loss: 0.9317 - val_accuracy: 0.6511\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 0.6431 - accuracy: 0.7441 - val_loss: 0.9796 - val_accuracy: 0.6475\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7105 - accuracy: 0.7281 - val_loss: 0.8673 - val_accuracy: 0.6763\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6317 - accuracy: 0.7705 - val_loss: 0.8802 - val_accuracy: 0.6871\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.7129 - accuracy: 0.7529 - val_loss: 0.9699 - val_accuracy: 0.6619\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6399 - accuracy: 0.7645 - val_loss: 0.8216 - val_accuracy: 0.6871\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.6625 - accuracy: 0.7497 - val_loss: 0.8201 - val_accuracy: 0.6906\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6469 - accuracy: 0.7429 - val_loss: 0.8099 - val_accuracy: 0.7122\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6178 - accuracy: 0.7705 - val_loss: 0.8286 - val_accuracy: 0.6835\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.5957 - accuracy: 0.7805 - val_loss: 0.7781 - val_accuracy: 0.7122\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6327 - accuracy: 0.7597 - val_loss: 1.1614 - val_accuracy: 0.6439\n",
            "Epoch 99/100\n",
            "76/79 [===========================>..] - ETA: 0s - loss: 0.6604 - accuracy: 0.7545Restoring model weights from the end of the best epoch: 49.\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.6634 - accuracy: 0.7529 - val_loss: 0.9074 - val_accuracy: 0.6619\n",
            "Epoch 99: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_pr_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hIzHD730J28",
        "outputId": "1b4ae138-1559-4589-8310-59088e7f8d58"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7791 - accuracy: 0.6926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7790585160255432, 0.692556619644165]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### deeplearning skip conection"
      ],
      "metadata": {
        "id": "EMSwpexS20_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense, Dropout, Add, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
        "    \"\"\"Creates an instance of a multi-layer perceptron model with skip connections.\n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        An MLP model instance with skip connections.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Dropout(rate=dropout_rate)(inputs)\n",
        "\n",
        "    for _ in range(layers - 1):\n",
        "        x = Dense(units=units, activation='swish')(x)\n",
        "        x = Add()([x, inputs])  # Add a skip connection here\n",
        "        x = Dropout(rate=dropout_rate)(x)\n",
        "\n",
        "    outputs = Dense(units=op_units, activation=op_activation)(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "PLaNhUbI20PU"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
        "\n",
        "    for _ in range(layers-1):\n",
        "        model.add(Dense(units=units, activation='swish'))\n",
        "        # model.add(BatchNormalization())\n",
        "        # model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(units=op_units, activation=op_activation))\n",
        "    return model"
      ],
      "metadata": {
        "id": "cW_KmOM45SEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_pr_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MafPuKu4q_5",
        "outputId": "b3e6bc7e-ae1b-4cab-a7e2-9ddc1b25985e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 모델 파라미터 설정\n",
        "layers = 8  # Dense 레이어 수\n",
        "units = 512  # 각 Dense 레이어의 뉴런 수\n",
        "dropout_rate = 0.0  # Dropout 레이어의 dropout 비율\n",
        "input_shape = (x_pr_train.shape[1],)  # 입력 데이터의 형태\n",
        "num_classes = 5  # 출력 클래스의 수\n",
        "\n",
        "print(input_shape)\n",
        "\n",
        "# MLP 모델 생성\n",
        "model = mlp_model(layers, units, dropout_rate, input_shape, num_classes)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # 옵티마이저 설정 (Adam 사용)\n",
        "    loss='sparse_categorical_crossentropy',  # 손실 함수\n",
        "    metrics=['accuracy']  # 평가 지표 (정확도)\n",
        ")\n",
        "\n",
        "# 모델 요약 정보 출력\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dhiIELYg3GvR",
        "outputId": "f023a2f6-e2cb-48c3-c533-2a6de0621146"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-0bff086d7a0a>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# MLP 모델 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 모델 컴파일\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-40ad3f61cc70>\u001b[0m in \u001b[0;36mmlp_model\u001b[0;34m(layers, units, dropout_rate, input_shape, num_classes)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'swish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add a skip connection here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/merging/base_merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m     75\u001b[0m                         \u001b[0;34m\"Inputs have incompatible shapes. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                         \u001b[0;34mf\"Received shapes {shape1} and {shape2}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (512,) and (100,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=50, verbose=1, restore_best_weights=True)\n",
        "history = model.fit(x_pr_train, y_train, verbose=1, callbacks=es, validation_split=0.1, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "scaOgOTo3Jv6",
        "outputId": "f37d9005-d6de-4e8d-eccb-9ae68c68fc5b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-eb56d185f276>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pr_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 512), found shape=(None, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_pr_val, y_val)"
      ],
      "metadata": {
        "id": "KhEmWzvD3JyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "fyQzW5_k69cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import SeparableConv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "\n",
        "def sepcnn_model(blocks,\n",
        "                 filters,\n",
        "                 kernel_size,\n",
        "                 embedding_dim,\n",
        "                 dropout_rate,\n",
        "                 pool_size,\n",
        "                 input_shape,\n",
        "                 num_classes,\n",
        "                 num_features,\n",
        "                 use_pretrained_embedding=False,\n",
        "                 is_embedding_trainable=False,\n",
        "                 embedding_matrix=None):\n",
        "    \"\"\"Creates an instance of a separable CNN model.\n",
        "\n",
        "    # Arguments\n",
        "        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n",
        "        filters: int, output dimension of the layers.\n",
        "        kernel_size: int, length of the convolution window.\n",
        "        embedding_dim: int, dimension of the embedding vectors.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        pool_size: int, factor by which to downscale input at MaxPooling layer.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "        num_features: int, number of words (embedding input dimension).\n",
        "        use_pretrained_embedding: bool, true if pre-trained embedding is on.\n",
        "        is_embedding_trainable: bool, true if embedding layer is trainable.\n",
        "        embedding_matrix: dict, dictionary with embedding coefficients.\n",
        "\n",
        "    # Returns\n",
        "        A sepCNN model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Add embedding layer. If pre-trained embedding is used add weights to the\n",
        "    # embeddings layer and set trainable to input is_embedding_trainable flag.\n",
        "    if use_pretrained_embedding:\n",
        "        model.add(Embedding(input_dim=num_features,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=input_shape[0],\n",
        "                            weights=[embedding_matrix],\n",
        "                            trainable=is_embedding_trainable))\n",
        "    else:\n",
        "        model.add(Embedding(input_dim=num_features,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=input_shape[0]))\n",
        "\n",
        "    for _ in range(blocks-1):\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(SeparableConv1D(filters=filters,\n",
        "                                  kernel_size=kernel_size,\n",
        "                                  activation='relu',\n",
        "                                  bias_initializer='random_uniform',\n",
        "                                  depthwise_initializer='random_uniform',\n",
        "                                  padding='same'))\n",
        "        model.add(MaxPooling1D(pool_size=pool_size))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(SeparableConv1D(filters=filters * 2,\n",
        "                              kernel_size=kernel_size,\n",
        "                              activation='relu',\n",
        "                              bias_initializer='random_uniform',\n",
        "                              depthwise_initializer='random_uniform',\n",
        "                              padding='same'))\n",
        "    model.add(GlobalAveragePooling1D())\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(Dense(op_units, activation=op_activation))\n",
        "    return model"
      ],
      "metadata": {
        "id": "pqlC0OOO68ID"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "max_features = x_mor_sequence_train.shape[1]  # Vocabulary size\n",
        "max_len = 500  # Maximum sequence length\n",
        "\n",
        "# Create the SepCNN model\n",
        "model = sepcnn_model(\n",
        "    blocks=4,\n",
        "    filters=256,\n",
        "    kernel_size=3,\n",
        "    embedding_dim=16,\n",
        "    dropout_rate=0.1,\n",
        "    pool_size=3,\n",
        "    input_shape=(max_len,),\n",
        "    num_classes=5,\n",
        "    num_features=max_features,\n",
        "    use_pretrained_embedding=False,\n",
        "    is_embedding_trainable=True\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuIzx-rV7F83",
        "outputId": "39ba295b-9601-413c-c182-628e150342c6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 16)           8000      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 500, 16)           0         \n",
            "                                                                 \n",
            " separable_conv1d (Separabl  (None, 500, 256)          4400      \n",
            " eConv1D)                                                        \n",
            "                                                                 \n",
            " separable_conv1d_1 (Separa  (None, 500, 256)          66560     \n",
            " bleConv1D)                                                      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 166, 256)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization_38 (Ba  (None, 166, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 166, 256)          0         \n",
            "                                                                 \n",
            " separable_conv1d_2 (Separa  (None, 166, 256)          66560     \n",
            " bleConv1D)                                                      \n",
            "                                                                 \n",
            " separable_conv1d_3 (Separa  (None, 166, 256)          66560     \n",
            " bleConv1D)                                                      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 55, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_39 (Ba  (None, 55, 256)           1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 55, 256)           0         \n",
            "                                                                 \n",
            " separable_conv1d_4 (Separa  (None, 55, 256)           66560     \n",
            " bleConv1D)                                                      \n",
            "                                                                 \n",
            " separable_conv1d_5 (Separa  (None, 55, 256)           66560     \n",
            " bleConv1D)                                                      \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 18, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_40 (Ba  (None, 18, 256)           1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " separable_conv1d_6 (Separa  (None, 18, 512)           132352    \n",
            " bleConv1D)                                                      \n",
            "                                                                 \n",
            " separable_conv1d_7 (Separa  (None, 18, 512)           264192    \n",
            " bleConv1D)                                                      \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 512)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 747381 (2.85 MB)\n",
            "Trainable params: 745845 (2.85 MB)\n",
            "Non-trainable params: 1536 (6.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=1, restore_best_weights=True)\n",
        "# history = model.fit(x_mor_sequence_train, y_train, verbose=1, callbacks=es, validation_split=0.1, epochs=epochs)\n",
        "model.fit(x_mor_sequence_train, y_train, verbose=1, epochs=epochs, batch_size=batch_size, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETmvt6bX7GBo",
        "outputId": "d716b5ad-7be9-4941-f03f-305f1d360f83"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "79/79 [==============================] - 26s 191ms/step - loss: 1.4310 - accuracy: 0.4350 - val_loss: 1.4620 - val_accuracy: 0.3705\n",
            "Epoch 2/80\n",
            "79/79 [==============================] - 11s 139ms/step - loss: 1.3801 - accuracy: 0.4358 - val_loss: 1.4333 - val_accuracy: 0.3705\n",
            "Epoch 3/80\n",
            "79/79 [==============================] - 10s 123ms/step - loss: 1.3785 - accuracy: 0.4358 - val_loss: 1.4544 - val_accuracy: 0.3705\n",
            "Epoch 4/80\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 1.3215 - accuracy: 0.4358 - val_loss: 1.4481 - val_accuracy: 0.3705\n",
            "Epoch 5/80\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 1.2063 - accuracy: 0.4482 - val_loss: 1.3917 - val_accuracy: 0.4137\n",
            "Epoch 6/80\n",
            "79/79 [==============================] - 4s 51ms/step - loss: 1.0822 - accuracy: 0.5510 - val_loss: 1.2618 - val_accuracy: 0.4676\n",
            "Epoch 7/80\n",
            "79/79 [==============================] - 5s 57ms/step - loss: 0.9945 - accuracy: 0.5838 - val_loss: 1.2793 - val_accuracy: 0.3777\n",
            "Epoch 8/80\n",
            "79/79 [==============================] - 3s 41ms/step - loss: 0.9524 - accuracy: 0.6002 - val_loss: 1.1274 - val_accuracy: 0.4748\n",
            "Epoch 9/80\n",
            "79/79 [==============================] - 4s 52ms/step - loss: 0.9327 - accuracy: 0.5974 - val_loss: 1.1200 - val_accuracy: 0.4784\n",
            "Epoch 10/80\n",
            "79/79 [==============================] - 3s 35ms/step - loss: 0.9019 - accuracy: 0.6162 - val_loss: 1.1143 - val_accuracy: 0.4892\n",
            "Epoch 11/80\n",
            "79/79 [==============================] - 2s 30ms/step - loss: 0.8967 - accuracy: 0.6002 - val_loss: 1.2377 - val_accuracy: 0.4065\n",
            "Epoch 12/80\n",
            "79/79 [==============================] - 3s 37ms/step - loss: 0.8659 - accuracy: 0.6182 - val_loss: 1.0503 - val_accuracy: 0.4712\n",
            "Epoch 13/80\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.8400 - accuracy: 0.6289 - val_loss: 1.0631 - val_accuracy: 0.5252\n",
            "Epoch 14/80\n",
            "79/79 [==============================] - 2s 30ms/step - loss: 0.8222 - accuracy: 0.6421 - val_loss: 1.1733 - val_accuracy: 0.4424\n",
            "Epoch 15/80\n",
            "79/79 [==============================] - 3s 34ms/step - loss: 0.8013 - accuracy: 0.6517 - val_loss: 1.0260 - val_accuracy: 0.5108\n",
            "Epoch 16/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.7766 - accuracy: 0.6489 - val_loss: 1.5949 - val_accuracy: 0.3417\n",
            "Epoch 17/80\n",
            "79/79 [==============================] - 3s 37ms/step - loss: 0.7763 - accuracy: 0.6713 - val_loss: 1.6452 - val_accuracy: 0.3669\n",
            "Epoch 18/80\n",
            "79/79 [==============================] - 3s 39ms/step - loss: 0.7598 - accuracy: 0.6669 - val_loss: 1.5724 - val_accuracy: 0.3453\n",
            "Epoch 19/80\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.7380 - accuracy: 0.6901 - val_loss: 1.9132 - val_accuracy: 0.3273\n",
            "Epoch 20/80\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.7195 - accuracy: 0.6849 - val_loss: 1.3835 - val_accuracy: 0.4784\n",
            "Epoch 21/80\n",
            "79/79 [==============================] - 2s 30ms/step - loss: 0.7160 - accuracy: 0.6917 - val_loss: 1.5342 - val_accuracy: 0.4029\n",
            "Epoch 22/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.6785 - accuracy: 0.7101 - val_loss: 2.0236 - val_accuracy: 0.4029\n",
            "Epoch 23/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.6723 - accuracy: 0.7221 - val_loss: 1.0592 - val_accuracy: 0.5576\n",
            "Epoch 24/80\n",
            "79/79 [==============================] - 4s 52ms/step - loss: 0.6470 - accuracy: 0.7329 - val_loss: 1.1280 - val_accuracy: 0.5540\n",
            "Epoch 25/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.6255 - accuracy: 0.7465 - val_loss: 0.9344 - val_accuracy: 0.6439\n",
            "Epoch 26/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.6152 - accuracy: 0.7525 - val_loss: 1.6208 - val_accuracy: 0.3777\n",
            "Epoch 27/80\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.5754 - accuracy: 0.7749 - val_loss: 1.7180 - val_accuracy: 0.3705\n",
            "Epoch 28/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.5569 - accuracy: 0.7901 - val_loss: 1.0500 - val_accuracy: 0.6259\n",
            "Epoch 29/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.5332 - accuracy: 0.7957 - val_loss: 1.0380 - val_accuracy: 0.6367\n",
            "Epoch 30/80\n",
            "79/79 [==============================] - 3s 30ms/step - loss: 0.5079 - accuracy: 0.8009 - val_loss: 1.0156 - val_accuracy: 0.6655\n",
            "Epoch 31/80\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 0.4912 - accuracy: 0.8017 - val_loss: 3.0320 - val_accuracy: 0.3921\n",
            "Epoch 32/80\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 0.4445 - accuracy: 0.8273 - val_loss: 1.8475 - val_accuracy: 0.4892\n",
            "Epoch 33/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.4615 - accuracy: 0.8169 - val_loss: 3.4921 - val_accuracy: 0.2842\n",
            "Epoch 34/80\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.4131 - accuracy: 0.8437 - val_loss: 3.1882 - val_accuracy: 0.3993\n",
            "Epoch 35/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.3997 - accuracy: 0.8509 - val_loss: 2.3129 - val_accuracy: 0.4173\n",
            "Epoch 36/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.3595 - accuracy: 0.8665 - val_loss: 3.6073 - val_accuracy: 0.3561\n",
            "Epoch 37/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.3909 - accuracy: 0.8541 - val_loss: 2.0413 - val_accuracy: 0.5396\n",
            "Epoch 38/80\n",
            "79/79 [==============================] - 2s 30ms/step - loss: 0.3393 - accuracy: 0.8784 - val_loss: 2.9786 - val_accuracy: 0.3309\n",
            "Epoch 39/80\n",
            "79/79 [==============================] - 2s 31ms/step - loss: 0.3219 - accuracy: 0.8816 - val_loss: 1.7653 - val_accuracy: 0.4928\n",
            "Epoch 40/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.3127 - accuracy: 0.8888 - val_loss: 3.8898 - val_accuracy: 0.4856\n",
            "Epoch 41/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.3128 - accuracy: 0.8900 - val_loss: 4.2522 - val_accuracy: 0.4568\n",
            "Epoch 42/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.3103 - accuracy: 0.8820 - val_loss: 1.5183 - val_accuracy: 0.6295\n",
            "Epoch 43/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.2929 - accuracy: 0.8936 - val_loss: 1.9343 - val_accuracy: 0.5719\n",
            "Epoch 44/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.2539 - accuracy: 0.9096 - val_loss: 1.8186 - val_accuracy: 0.5899\n",
            "Epoch 45/80\n",
            "79/79 [==============================] - 2s 25ms/step - loss: 0.2351 - accuracy: 0.9184 - val_loss: 1.5984 - val_accuracy: 0.6295\n",
            "Epoch 46/80\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 0.2215 - accuracy: 0.9192 - val_loss: 1.7052 - val_accuracy: 0.6115\n",
            "Epoch 47/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.2299 - accuracy: 0.9172 - val_loss: 2.3421 - val_accuracy: 0.5216\n",
            "Epoch 48/80\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.2369 - accuracy: 0.9228 - val_loss: 2.2631 - val_accuracy: 0.5647\n",
            "Epoch 49/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.2120 - accuracy: 0.9256 - val_loss: 2.1907 - val_accuracy: 0.5899\n",
            "Epoch 50/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1859 - accuracy: 0.9364 - val_loss: 1.2569 - val_accuracy: 0.6547\n",
            "Epoch 51/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.1762 - accuracy: 0.9432 - val_loss: 3.9939 - val_accuracy: 0.4748\n",
            "Epoch 52/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1772 - accuracy: 0.9364 - val_loss: 3.3013 - val_accuracy: 0.5252\n",
            "Epoch 53/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1779 - accuracy: 0.9356 - val_loss: 1.9493 - val_accuracy: 0.5899\n",
            "Epoch 54/80\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.1503 - accuracy: 0.9512 - val_loss: 1.3997 - val_accuracy: 0.6763\n",
            "Epoch 55/80\n",
            "79/79 [==============================] - 2s 27ms/step - loss: 0.1556 - accuracy: 0.9440 - val_loss: 1.4389 - val_accuracy: 0.6799\n",
            "Epoch 56/80\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 0.1730 - accuracy: 0.9408 - val_loss: 5.9263 - val_accuracy: 0.3165\n",
            "Epoch 57/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.2923 - accuracy: 0.9000 - val_loss: 2.6193 - val_accuracy: 0.5252\n",
            "Epoch 58/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1490 - accuracy: 0.9436 - val_loss: 1.2567 - val_accuracy: 0.6942\n",
            "Epoch 59/80\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.1784 - accuracy: 0.9396 - val_loss: 3.8976 - val_accuracy: 0.3849\n",
            "Epoch 60/80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 0.1371 - accuracy: 0.9508 - val_loss: 1.8885 - val_accuracy: 0.6655\n",
            "Epoch 61/80\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.1246 - accuracy: 0.9564 - val_loss: 1.8853 - val_accuracy: 0.6259\n",
            "Epoch 62/80\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.1138 - accuracy: 0.9592 - val_loss: 7.4077 - val_accuracy: 0.2950\n",
            "Epoch 63/80\n",
            "79/79 [==============================] - 2s 22ms/step - loss: 0.1174 - accuracy: 0.9616 - val_loss: 3.8958 - val_accuracy: 0.4424\n",
            "Epoch 64/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.1306 - accuracy: 0.9560 - val_loss: 2.5631 - val_accuracy: 0.6151\n",
            "Epoch 65/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.1243 - accuracy: 0.9528 - val_loss: 5.2433 - val_accuracy: 0.3993\n",
            "Epoch 66/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.1143 - accuracy: 0.9620 - val_loss: 2.7954 - val_accuracy: 0.5108\n",
            "Epoch 67/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.1161 - accuracy: 0.9576 - val_loss: 2.2026 - val_accuracy: 0.5935\n",
            "Epoch 68/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.1725 - accuracy: 0.9420 - val_loss: 1.9566 - val_accuracy: 0.6295\n",
            "Epoch 69/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1010 - accuracy: 0.9636 - val_loss: 2.1931 - val_accuracy: 0.6583\n",
            "Epoch 70/80\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 0.1554 - accuracy: 0.9484 - val_loss: 4.2529 - val_accuracy: 0.4892\n",
            "Epoch 71/80\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.1270 - accuracy: 0.9548 - val_loss: 2.8368 - val_accuracy: 0.5144\n",
            "Epoch 72/80\n",
            "79/79 [==============================] - 2s 26ms/step - loss: 0.0881 - accuracy: 0.9696 - val_loss: 2.9947 - val_accuracy: 0.5504\n",
            "Epoch 73/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0910 - accuracy: 0.9664 - val_loss: 2.0009 - val_accuracy: 0.6799\n",
            "Epoch 74/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0990 - accuracy: 0.9656 - val_loss: 5.4821 - val_accuracy: 0.4209\n",
            "Epoch 75/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.1098 - accuracy: 0.9588 - val_loss: 1.8374 - val_accuracy: 0.6763\n",
            "Epoch 76/80\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 0.0882 - accuracy: 0.9664 - val_loss: 10.3874 - val_accuracy: 0.2554\n",
            "Epoch 77/80\n",
            "79/79 [==============================] - 2s 24ms/step - loss: 0.0660 - accuracy: 0.9788 - val_loss: 3.0116 - val_accuracy: 0.5612\n",
            "Epoch 78/80\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.1363 - accuracy: 0.9540 - val_loss: 2.0187 - val_accuracy: 0.6547\n",
            "Epoch 79/80\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.1308 - accuracy: 0.9568 - val_loss: 3.4705 - val_accuracy: 0.5540\n",
            "Epoch 80/80\n",
            "79/79 [==============================] - 2s 23ms/step - loss: 0.0819 - accuracy: 0.9708 - val_loss: 2.5483 - val_accuracy: 0.6007\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x785e0466b640>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(x_mor_sequence_val)\n",
        "y_pred = tf.argmax(y_pred, axis=1).numpy()\n",
        "# y_val = tf.argmax(y_val, axis=1).numpy()\n",
        "report = classification_report(y_val, y_pred)\n",
        "model.evaluate(x_mor_sequence_val, y_val)\n",
        "print(report)\n",
        "print(\"accaurcy :\", accuracy_score(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toAQskGI7GEn",
        "outputId": "c63d9510-57d2-4644-a053-4162c460f3fd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 1s 15ms/step\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 2.3431 - accuracy: 0.6440\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.94      0.71       392\n",
            "           1       0.77      0.43      0.55       179\n",
            "           2       0.88      0.24      0.37       195\n",
            "           3       0.73      0.60      0.66       130\n",
            "           4       0.93      0.90      0.92        31\n",
            "\n",
            "    accuracy                           0.64       927\n",
            "   macro avg       0.78      0.62      0.64       927\n",
            "weighted avg       0.71      0.64      0.61       927\n",
            "\n",
            "accaurcy : 0.6440129449838188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "8OsEMCNR8fnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# LSTM 모델 정의\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=x_mor_sequence_train.shape[1], output_dim=16, input_length=x_mor_sequence_train.shape[1]))\n",
        "model.add(LSTM(64, return_sequences=True))  # LSTM 레이어 추가\n",
        "model.add(SimpleRNN(32))\n",
        "# model.add(SimpleRNN(64, return_sequences=True))\n",
        "# model.add(LSTM(128, return_sequences=True))  # LSTM 레이어 추가\n",
        "# model.add(SimpleRNN(128))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8kttzk9ApOV",
        "outputId": "04c58e7f-c162-490b-8a67-0366acc5d8b5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 500, 16)           8000      \n",
            "                                                                 \n",
            " lstm_20 (LSTM)              (None, 500, 64)           20736     \n",
            "                                                                 \n",
            " simple_rnn_4 (SimpleRNN)    (None, 128)               24704     \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54085 (211.27 KB)\n",
            "Trainable params: 54085 (211.27 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=1, restore_best_weights=True)\n",
        "model.fit(x_mor_sequence_train, y_train, epochs=20, validation_split=0.1, callbacks=es)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyvBeFL18ifO",
        "outputId": "5b970677-0aad-4437-9467-3cac954dad97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "79/79 [==============================] - 55s 663ms/step - loss: 1.4010 - accuracy: 0.4266 - val_loss: 1.3402 - val_accuracy: 0.3669\n",
            "Epoch 2/20\n",
            "79/79 [==============================] - 50s 628ms/step - loss: 1.1891 - accuracy: 0.5142 - val_loss: 1.1451 - val_accuracy: 0.5036\n",
            "Epoch 3/20\n",
            "79/79 [==============================] - 48s 612ms/step - loss: 1.2681 - accuracy: 0.4902 - val_loss: 1.3823 - val_accuracy: 0.3813\n",
            "Epoch 4/20\n",
            "79/79 [==============================] - 48s 614ms/step - loss: 1.2097 - accuracy: 0.4810 - val_loss: 1.2358 - val_accuracy: 0.4137\n",
            "Epoch 5/20\n",
            "79/79 [==============================] - 50s 624ms/step - loss: 1.1370 - accuracy: 0.5326 - val_loss: 1.2305 - val_accuracy: 0.4928\n",
            "Epoch 6/20\n",
            "79/79 [==============================] - 47s 585ms/step - loss: 1.0929 - accuracy: 0.5330 - val_loss: 1.1603 - val_accuracy: 0.5144\n",
            "Epoch 7/20\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 1.0700 - accuracy: 0.5358 - val_loss: 1.2710 - val_accuracy: 0.4820\n",
            "Epoch 8/20\n",
            "79/79 [==============================] - 45s 578ms/step - loss: 1.0343 - accuracy: 0.5574 - val_loss: 1.1619 - val_accuracy: 0.4928\n",
            "Epoch 9/20\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 0.9947 - accuracy: 0.5682 - val_loss: 1.0542 - val_accuracy: 0.5612\n",
            "Epoch 10/20\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 1.0014 - accuracy: 0.5694 - val_loss: 1.0799 - val_accuracy: 0.5252\n",
            "Epoch 11/20\n",
            "65/79 [=======================>......] - ETA: 7s - loss: 1.0759 - accuracy: 0.5418"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_mor_sequence_val, y_val)\n",
        "print(f\"val loss: {loss:.4f}, val accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "5rWjUHO98ihe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KyyilGGj8ijm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}